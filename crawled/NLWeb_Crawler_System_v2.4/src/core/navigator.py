import asyncio
import logging
from datetime import datetime, timedelta
from typing import Optional, Dict, Any, Tuple, Callable, Awaitable
from pathlib import Path

from config import settings

class DateNavigator:
    """
    æ—¥æœŸå°èˆªå™¨
    ä½¿ç”¨äºŒåˆ†æœå°‹æ¼”ç®—æ³•å®šä½ç›®æ¨™æ—¥æœŸå°æ‡‰çš„æ–‡ç«  ID
    
    âœ… FIX #NAVIGATOR-SCALING-FIX: æ™ºèƒ½ç¯„åœä¼°ç®—
    âœ… FIX #NAVIGATOR-DIRECT-CALC: ä¸­æ™‚ ID ç›´ç®—é‚è¼¯ï¼ˆTurbo Modeï¼‰
    âœ… FIX #NAVIGATOR-CNA-SUPPORT: æ”¯æ´ä¸­å¤®ç¤¾ 12 ç¢¼ ID
    
    æ”¯æ´å…©ç¨® ID æ ¼å¼ï¼š
    1. æµæ°´è™Ÿå‹ (Sequential)ï¼šå¦‚ LTN (4567890) - ä½¿ç”¨äºŒåˆ†æœå°‹
    2. æ—¥æœŸå‹ (Date-based)ï¼šå¦‚ ChinaTimes (20251212001234)ã€CNA (202512290031) - ç›´æ¥è¨ˆç®—
    """
    
    # ID é¡å‹åˆ¤æ–·é–¾å€¼
    ID_TYPE_THRESHOLD = 10_000_000  # 1000 è¬
    
    # æœå°‹ç¯„åœè¨­å®š
    SEQUENTIAL_SEARCH_RANGE = 1_000_000  # æµæ°´è™Ÿå‹å›æº¯ç¯„åœï¼ˆ100 è¬ï¼‰
    DATE_BASED_SEARCH_MARGIN = 10_000_000  # æ—¥æœŸå‹å®‰å…¨é‚Šç•Œï¼ˆ1000 è¬ï¼‰
    
    # âœ… FIX #NAVIGATOR-CNA-SUPPORT: åŠ å…¥ CNA
    TURBO_MODE_SOURCES = ['chinatimes', 'cna']  # æ”¯æ´ç›´ç®—çš„ä¾†æº
    
    def __init__(
        self,
        parser_get_date: Callable[[int], Awaitable[Optional[datetime]]],
        source_name: str = "unknown"
    ):
        """
        åˆå§‹åŒ–æ—¥æœŸå°èˆªå™¨
        
        Args:
            parser_get_date: Parser æä¾›çš„ç²å–æ—¥æœŸå‡½å¼ï¼Œæ¥æ”¶ article_idï¼Œè¿”å›æ—¥æœŸæˆ– None
            source_name: æ–°èä¾†æºåç¨±ï¼ˆç”¨æ–¼æ—¥èªŒï¼‰
        """
        self.parser_get_date = parser_get_date
        self.source_name = source_name
        self.logger = logging.getLogger(f"{self.__class__.__name__}_{source_name}")
        
        # è¨­å®šæ—¥èªŒè™•ç†å™¨
        if not self.logger.handlers:
            self._setup_logger()
        
        # äºŒåˆ†æœå°‹è¨­å®š
        self.max_search_iterations = 50  # äºŒåˆ†æœå°‹æœ€å¤§è¿­ä»£æ¬¡æ•¸
        self.max_skip_attempts = 10  # é‡åˆ°ç©ºè™Ÿæ™‚æœ€å¤§å˜—è©¦æ¬¡æ•¸
        self.search_tolerance_days = 1  # æœå°‹å®¹å¿åº¦ï¼ˆå¤©ï¼‰
    
    def _setup_logger(self) -> None:
        """è¨­ç½®æ—¥èªŒè™•ç†å™¨"""
        settings.LOG_DIR.mkdir(parents=True, exist_ok=True)
        
        import time
        log_file = settings.LOG_DIR / f"navigator_{self.source_name}_{time.strftime('%Y%m%d')}.log"
        file_handler = logging.FileHandler(log_file, encoding='utf-8')
        console_handler = logging.StreamHandler()
        
        formatter = logging.Formatter(
            settings.LOG_FORMAT,
            datefmt=settings.LOG_DATE_FORMAT
        )
        file_handler.setFormatter(formatter)
        console_handler.setFormatter(formatter)
        
        self.logger.addHandler(file_handler)
        self.logger.addHandler(console_handler)
        self.logger.setLevel(settings.LOG_LEVEL)
    
    def _detect_id_format(self, article_id: int) -> str:
        """
        åµæ¸¬ ID æ ¼å¼é¡å‹
        
        ç­–ç•¥ï¼š
        1. å¦‚æœ ID < 10,000,000ï¼šå‡è¨­æ˜¯æµæ°´è™Ÿï¼ˆLTN é¡å‹ï¼‰
        2. å¦‚æœ ID >= 10,000,000 ä¸”å‰ 8 ä½å¯è§£æç‚ºæ—¥æœŸï¼šæ—¥æœŸå‹ï¼ˆChinaTimes/CNA é¡å‹ï¼‰
        3. å¦å‰‡ï¼šæµæ°´è™Ÿï¼ˆä¿å®ˆç­–ç•¥ï¼‰
        
        Args:
            article_id: æ–‡ç«  ID
            
        Returns:
            'sequential' æˆ– 'date_based'
        """
        if article_id < self.ID_TYPE_THRESHOLD:
            return 'sequential'
        
        # å˜—è©¦è§£æå‰ 8 ä½ç‚ºæ—¥æœŸ
        try:
            id_str = str(article_id)
            if len(id_str) >= 8:
                date_str = id_str[:8]
                datetime.strptime(date_str, '%Y%m%d')
                return 'date_based'
        except (ValueError, IndexError):
            pass
        
        # ç„¡æ³•ç¢ºå®šï¼Œä½¿ç”¨ä¿å®ˆç­–ç•¥
        return 'sequential'
    
    def _parse_date_from_id(self, article_id: int) -> Optional[datetime]:
        """
        å¾æ—¥æœŸå‹ ID ä¸­è§£ææ—¥æœŸ
        
        Args:
            article_id: æ–‡ç«  IDï¼ˆå¦‚ 20251212001234 æˆ– 202512290031ï¼‰
            
        Returns:
            è§£æå‡ºçš„æ—¥æœŸï¼Œæˆ– Noneï¼ˆå¦‚æœç„¡æ³•è§£æï¼‰
        """
        try:
            id_str = str(article_id)
            date_str = id_str[:8]  # YYYYMMDD
            return datetime.strptime(date_str, '%Y%m%d')
        except (ValueError, IndexError):
            return None
    
    def _is_turbo_mode_enabled(self) -> bool:
        """
        åˆ¤æ–·æ˜¯å¦å•Ÿç”¨ Turbo Modeï¼ˆç›´ç®—é‚è¼¯ï¼‰
        
        âœ… FIX #NAVIGATOR-CNA-SUPPORT: æ”¯æ´ ChinaTimes å’Œ CNA
        
        Returns:
            True å¦‚æœæ‡‰è©²ä½¿ç”¨ç›´ç®—é‚è¼¯
        """
        return self.source_name in self.TURBO_MODE_SOURCES
    
    def _calculate_id_range_direct(
        self,
        start_date: datetime,
        end_date: datetime
    ) -> Tuple[int, int]:
        """
        ç›´æ¥è¨ˆç®—æ—¥æœŸç¯„åœå°æ‡‰çš„ ID ç¯„åœï¼ˆTurbo Modeï¼‰
        
        âœ… FIX #NAVIGATOR-CNA-SUPPORT: æ”¯æ´ä¸åŒæµæ°´è™Ÿé•·åº¦
        
        ç­–ç•¥ï¼š
        - CNA: YYYYMMDD + 0001-9999 (4ç¢¼)
        - ChinaTimes: YYYYMMDD + 000001-999999 (6ç¢¼)
        
        Args:
            start_date: é–‹å§‹æ—¥æœŸ
            end_date: çµæŸæ—¥æœŸ
            
        Returns:
            (start_id, end_id)
        """
        # âœ… FIX #NAVIGATOR-CNA-SUPPORT: æ ¹æ“šä¾†æºé¸æ“‡æµæ°´è™Ÿé•·åº¦
        if self.source_name == 'cna':
            # ä¸­å¤®ç¤¾ï¼šYYYYMMDD + 4ç¢¼ (0001 ~ 9999)
            start_suffix = '0001'
            end_suffix = '9999'
            id_length = 12
        else:
            # é è¨­ (å¦‚ä¸­æ™‚)ï¼šYYYYMMDD + 6ç¢¼ (000001 ~ 999999)
            start_suffix = '000001'
            end_suffix = '999999'
            id_length = 14
        
        # æ§‹å»º ID
        start_str = start_date.strftime('%Y%m%d') + start_suffix
        end_str = end_date.strftime('%Y%m%d') + end_suffix
        
        start_id = int(start_str)
        end_id = int(end_str)
        
        self.logger.info(f"âš¡ï¸ [Turbo Mode] Direct calculation enabled")
        self.logger.info(f"   Source: {self.source_name} (ID length: {id_length})")
        self.logger.info(f"   Start date: {start_date.strftime('%Y-%m-%d')} â†’ ID: {start_id:,}")
        self.logger.info(f"   End date:   {end_date.strftime('%Y-%m-%d')} â†’ ID: {end_id:,}")
        self.logger.info(f"   Total range: {end_id - start_id + 1:,} IDs")
        self.logger.info(f"   Skipped binary search (instant calculation)")
        
        return (start_id, end_id)
    
    def _estimate_search_range(
        self,
        latest_id: int,
        target_date: datetime
    ) -> Tuple[int, int]:
        """
        æ™ºèƒ½ä¼°ç®—æœå°‹ç¯„åœ
        
        âœ… FIX #NAVIGATOR-SCALING-FIX æ ¸å¿ƒé‚è¼¯
        âœ… FIX #NAVIGATOR-CNA-SUPPORT: æ”¯æ´ä¸åŒæµæ°´è™Ÿé•·åº¦
        
        ç­–ç•¥ï¼š
        1. æµæ°´è™Ÿå‹ï¼ˆLTN/UDNï¼‰ï¼šä½¿ç”¨å›ºå®šå›æº¯ç¯„åœï¼ˆ100 è¬ï¼‰
        2. æ—¥æœŸå‹ï¼ˆChinaTimes/CNAï¼‰ï¼šå¾ ID ä¸­è§£ææ—¥æœŸï¼Œæ§‹å»ºç²¾ç¢ºç¯„åœ
        
        Args:
            latest_id: æœ€æ–°æ–‡ç«  ID
            target_date: ç›®æ¨™æ—¥æœŸ
            
        Returns:
            (lower_bound, upper_bound) æœå°‹ç¯„åœ
        """
        id_format = self._detect_id_format(latest_id)
        
        if id_format == 'sequential':
            # ========== æµæ°´è™Ÿå‹ï¼ˆLTN/UDNï¼‰==========
            lower_bound = max(0, latest_id - self.SEQUENTIAL_SEARCH_RANGE)
            upper_bound = latest_id
            
            self.logger.info(f"ğŸ“Š Detected sequential ID format (LTN/UDN-like)")
            self.logger.info(f"   Latest ID: {latest_id:,}")
            self.logger.info(f"   Search range: [{lower_bound:,}, {upper_bound:,}]")
            self.logger.info(f"   Range size: {upper_bound - lower_bound:,} IDs")
            
        else:
            # ========== æ—¥æœŸå‹ï¼ˆChinaTimes/CNAï¼‰==========
            id_date = self._parse_date_from_id(latest_id)
            
            if id_date is None:
                # ç„¡æ³•è§£æï¼Œé€€å›åˆ°ä¿å®ˆç­–ç•¥
                self.logger.warning(f"âš ï¸  Could not parse date from ID {latest_id}, using conservative range")
                lower_bound = max(0, latest_id - self.DATE_BASED_SEARCH_MARGIN)
                upper_bound = latest_id
            else:
                # æ§‹å»ºç›®æ¨™æ—¥æœŸçš„ ID ç¯„åœ
                target_date_str = target_date.strftime('%Y%m%d')
                
                # âœ… FIX #NAVIGATOR-CNA-SUPPORT: æ ¹æ“šä¾†æºé¸æ“‡æµæ°´è™Ÿé•·åº¦
                if self.source_name == 'cna':
                    # ä¸­å¤®ç¤¾ï¼š4 ç¢¼æµæ°´è™Ÿ
                    lower_bound = int(target_date_str + '0000')
                    upper_bound = int(target_date_str + '9999')
                else:
                    # é è¨­ (å¦‚ä¸­æ™‚)ï¼š6 ç¢¼æµæ°´è™Ÿ
                    lower_bound = int(target_date_str + '000000')
                    upper_bound = int(target_date_str + '999999')
                
                self.logger.info(f"ğŸ“Š Detected date-based ID format (ChinaTimes/CNA-like)")
                self.logger.info(f"   Latest ID: {latest_id:,} (Date: {id_date.strftime('%Y-%m-%d')})")
                self.logger.info(f"   Target date: {target_date.strftime('%Y-%m-%d')}")
                self.logger.info(f"   Search range: [{lower_bound:,}, {upper_bound:,}]")
                self.logger.info(f"   Range size: {upper_bound - lower_bound:,} IDs (~1 day)")
        
        return (lower_bound, upper_bound)
    
    async def find_article_by_date(
        self,
        target_date: datetime,
        min_id: int,
        max_id: int
    ) -> Optional[int]:
        """
        ä½¿ç”¨äºŒåˆ†æœå°‹æ‰¾åˆ°æœ€æ¥è¿‘ç›®æ¨™æ—¥æœŸçš„æ–‡ç«  ID
        
        Args:
            target_date: ç›®æ¨™æ—¥æœŸ
            min_id: æœå°‹ç¯„åœæœ€å° ID
            max_id: æœå°‹ç¯„åœæœ€å¤§ ID
            
        Returns:
            æ‰¾åˆ°çš„æ–‡ç«  IDï¼Œæˆ– Noneï¼ˆå¦‚æœæœå°‹å¤±æ•—ï¼‰
        """
        self.logger.info(f"ğŸ” Starting binary search for date: {target_date.strftime('%Y-%m-%d')}")
        self.logger.info(f"   Search range: [{min_id:,}, {max_id:,}]")
        
        left = min_id
        right = max_id
        best_match_id = None
        best_match_diff = float('inf')
        
        iteration = 0
        
        while left <= right and iteration < self.max_search_iterations:
            iteration += 1
            mid = (left + right) // 2
            
            self.logger.debug(f"Iteration {iteration}: Checking ID {mid:,} (range: [{left:,}, {right:,}])")
            
            # ç²å–ä¸­é–“ ID çš„æ—¥æœŸ
            mid_date = await self._get_valid_date(mid)
            
            if mid_date is None:
                self.logger.warning(f"âš ï¸  Could not get valid date around ID {mid:,}, narrowing search range")
                # ç„¡æ³•ç²å–æœ‰æ•ˆæ—¥æœŸï¼Œç¸®å°æœå°‹ç¯„åœ
                if right - left <= 1:
                    break
                # å˜—è©¦æœå°‹å³åŠéƒ¨
                left = mid + 1
                continue
            
            # è¨ˆç®—æ—¥æœŸå·®ç•°
            date_diff = (mid_date - target_date).total_seconds()
            abs_diff = abs(date_diff)
            
            self.logger.debug(f"   ID {mid:,} -> Date: {mid_date.strftime('%Y-%m-%d %H:%M:%S')}, Diff: {date_diff / 86400:.2f} days")
            
            # æ›´æ–°æœ€ä½³åŒ¹é…
            if abs_diff < best_match_diff:
                best_match_diff = abs_diff
                best_match_id = mid
                self.logger.info(f"âœ¨ New best match: ID {mid:,}, Date: {mid_date.strftime('%Y-%m-%d')}, Diff: {abs_diff / 86400:.2f} days")
            
            # æª¢æŸ¥æ˜¯å¦å·²è¶³å¤ æ¥è¿‘
            if abs_diff <= self.search_tolerance_days * 86400:  # è½‰æ›ç‚ºç§’
                self.logger.info(f"âœ… Found close match within tolerance: ID {mid:,}")
                return mid
            
            # èª¿æ•´æœå°‹ç¯„åœ
            if date_diff > 0:
                # mid_date åœ¨ target_date ä¹‹å¾Œï¼Œæœå°‹å·¦åŠéƒ¨
                right = mid - 1
            else:
                # mid_date åœ¨ target_date ä¹‹å‰ï¼Œæœå°‹å³åŠéƒ¨
                left = mid + 1
        
        if best_match_id is not None:
            self.logger.info(f"ğŸ¯ Binary search completed: Best match ID {best_match_id:,}, Diff: {best_match_diff / 86400:.2f} days")
            return best_match_id
        else:
            self.logger.error(f"âŒ Binary search failed: No valid article found in range [{min_id:,}, {max_id:,}]")
            return None
    
    async def _get_valid_date(self, article_id: int) -> Optional[datetime]:
        """
        ç²å–æœ‰æ•ˆçš„æ–‡ç« æ—¥æœŸï¼Œè™•ç† ID å¤±æ•ˆçš„æƒ…æ³
        
        Args:
            article_id: æ–‡ç«  ID
            
        Returns:
            æ–‡ç« æ—¥æœŸï¼Œæˆ– Noneï¼ˆå¦‚æœç„¡æ³•ç²å–ï¼‰
        """
        # é¦–å…ˆå˜—è©¦åŸå§‹ ID
        date = await self.parser_get_date(article_id)
        if date is not None:
            return date
        
        self.logger.debug(f"ID {article_id:,} is invalid, trying nearby IDs...")
        
        # å¦‚æœåŸå§‹ ID å¤±æ•ˆï¼Œå˜—è©¦é™„è¿‘çš„ ID
        for offset in range(1, self.max_skip_attempts + 1):
            # å˜—è©¦ +offset
            try_id_plus = article_id + offset
            date = await self.parser_get_date(try_id_plus)
            if date is not None:
                self.logger.debug(f"   Found valid ID: {try_id_plus:,} (original + {offset})")
                return date
            
            # å˜—è©¦ -offset
            try_id_minus = article_id - offset
            if try_id_minus > 0:
                date = await self.parser_get_date(try_id_minus)
                if date is not None:
                    self.logger.debug(f"   Found valid ID: {try_id_minus:,} (original - {offset})")
                    return date
        
        self.logger.warning(f"âš ï¸  Could not find valid article near ID {article_id:,} (tried Â±{self.max_skip_attempts})")
        return None
    
    async def find_date_range(
        self,
        start_date: datetime,
        end_date: datetime,
        min_id: Optional[int] = None,
        max_id: Optional[int] = None
    ) -> Optional[Tuple[int, int]]:
        """
        æ‰¾åˆ°æ—¥æœŸç¯„åœå°æ‡‰çš„æ–‡ç«  ID ç¯„åœ
        
        âœ… FIX #NAVIGATOR-SCALING-FIX: æ”¯æ´æ™ºèƒ½ç¯„åœä¼°ç®—
        âœ… FIX #NAVIGATOR-DIRECT-CALC: æ”¯æ´ Turbo Modeï¼ˆç›´ç®—é‚è¼¯ï¼‰
        âœ… FIX #NAVIGATOR-CNA-SUPPORT: æ”¯æ´ä¸­å¤®ç¤¾ 12 ç¢¼ ID
        
        Args:
            start_date: é–‹å§‹æ—¥æœŸ
            end_date: çµæŸæ—¥æœŸ
            min_id: æœå°‹ç¯„åœæœ€å° IDï¼ˆå¯é¸ï¼Œæœªæä¾›å‰‡è‡ªå‹•ä¼°ç®—ï¼‰
            max_id: æœå°‹ç¯„åœæœ€å¤§ IDï¼ˆå¯é¸ï¼Œæœªæä¾›å‰‡éœ€è¦å¾å¤–éƒ¨ç²å–ï¼‰
            
        Returns:
            (start_id, end_id) æˆ– Noneï¼ˆå¦‚æœæœå°‹å¤±æ•—ï¼‰
        """
        self.logger.info(f"ğŸ” Finding ID range for date range: {start_date.strftime('%Y-%m-%d')} to {end_date.strftime('%Y-%m-%d')}")
        
        # âœ… FIX #NAVIGATOR-DIRECT-CALC: Turbo Mode å„ªå…ˆ
        if self._is_turbo_mode_enabled():
            return self._calculate_id_range_direct(start_date, end_date)
        
        # ========== å‚³çµ±æ¨¡å¼ï¼ˆäºŒåˆ†æœå°‹ï¼‰==========
        
        # æª¢æŸ¥ max_id æ˜¯å¦æä¾›
        if max_id is None:
            self.logger.error("âŒ max_id is required for range estimation")
            self.logger.error("   Please provide max_id (e.g., latest article ID)")
            return None
        
        # æ™ºèƒ½ä¼°ç®—æœå°‹ç¯„åœ
        # ç‚ºé–‹å§‹æ—¥æœŸä¼°ç®—ç¯„åœ
        start_min_id, start_max_id = self._estimate_search_range(max_id, start_date)
        
        # æ‰¾åˆ°é–‹å§‹æ—¥æœŸå°æ‡‰çš„ ID
        self.logger.info(f"")
        self.logger.info(f"ğŸ“ Locating start date: {start_date.strftime('%Y-%m-%d')}")
        start_id = await self.find_article_by_date(start_date, start_min_id, start_max_id)
        if start_id is None:
            self.logger.error("âŒ Could not find start ID")
            return None
        
        # ç‚ºçµæŸæ—¥æœŸä¼°ç®—ç¯„åœ
        end_min_id, end_max_id = self._estimate_search_range(max_id, end_date)
        
        # æ‰¾åˆ°çµæŸæ—¥æœŸå°æ‡‰çš„ ID
        self.logger.info(f"")
        self.logger.info(f"ğŸ“ Locating end date: {end_date.strftime('%Y-%m-%d')}")
        end_id = await self.find_article_by_date(end_date, end_min_id, end_max_id)
        if end_id is None:
            self.logger.error("âŒ Could not find end ID")
            return None
        
        # ç¢ºä¿ start_id <= end_id
        if start_id > end_id:
            start_id, end_id = end_id, start_id
        
        self.logger.info(f"")
        self.logger.info(f"âœ… Found ID range: [{start_id:,}, {end_id:,}]")
        self.logger.info(f"   Total articles: ~{end_id - start_id + 1:,}")
        
        return (start_id, end_id)
    
    async def estimate_id_range(
        self,
        sample_ids: list[int],
        target_date: datetime
    ) -> Optional[Tuple[int, int]]:
        """
        åŸºæ–¼æ¨£æœ¬ ID ä¼°ç®—ç›®æ¨™æ—¥æœŸçš„ ID ç¯„åœ
        
        Args:
            sample_ids: æ¨£æœ¬ ID åˆ—è¡¨ï¼ˆè‡³å°‘éœ€è¦ 2 å€‹ï¼‰
            target_date: ç›®æ¨™æ—¥æœŸ
            
        Returns:
            ä¼°ç®—çš„ (min_id, max_id) ç¯„åœï¼Œæˆ– Noneï¼ˆå¦‚æœä¼°ç®—å¤±æ•—ï¼‰
        """
        if len(sample_ids) < 2:
            self.logger.error("âŒ Need at least 2 sample IDs for estimation")
            return None
        
        self.logger.info(f"ğŸ“Š Estimating ID range for {target_date.strftime('%Y-%m-%d')} based on {len(sample_ids)} samples")
        
        # æ”¶é›†æœ‰æ•ˆçš„æ¨£æœ¬é»
        samples = []
        for sample_id in sample_ids:
            date = await self._get_valid_date(sample_id)
            if date is not None:
                samples.append((sample_id, date))
        
        if len(samples) < 2:
            self.logger.error("âŒ Not enough valid samples for estimation")
            return None
        
        # æŒ‰æ—¥æœŸæ’åº
        samples.sort(key=lambda x: x[1])
        
        # è¨ˆç®—å¹³å‡æ¯æ—¥ ID å¢é•·ç‡
        total_id_diff = samples[-1][0] - samples[0][0]
        total_time_diff = (samples[-1][1] - samples[0][1]).total_seconds()
        
        if total_time_diff <= 0:
            self.logger.error("âŒ Invalid time range in samples")
            return None
        
        ids_per_second = total_id_diff / total_time_diff
        ids_per_day = ids_per_second * 86400
        
        self.logger.info(f"   Estimated growth rate: {ids_per_day:,.2f} IDs per day")
        
        # åŸºæ–¼æœ€è¿‘çš„æ¨£æœ¬é»ä¼°ç®—ç›®æ¨™æ—¥æœŸçš„ ID
        closest_sample = min(samples, key=lambda x: abs((x[1] - target_date).total_seconds()))
        time_diff_seconds = (target_date - closest_sample[1]).total_seconds()
        estimated_id = int(closest_sample[0] + (ids_per_second * time_diff_seconds))
        
        # è¨­å®šæœå°‹ç¯„åœï¼ˆÂ±3 å¤©ä½œç‚ºå®‰å…¨é‚Šç•Œï¼‰
        range_margin = int(abs(ids_per_day) * 3)  # 3 å¤©çš„ç¯„åœ
        min_id = max(1, estimated_id - range_margin)
        max_id = estimated_id + range_margin
        
        self.logger.info(f"   Estimated ID: {estimated_id:,}")
        self.logger.info(f"   Search range: [{min_id:,}, {max_id:,}] (Â±3 days)")
        
        return (min_id, max_id)
