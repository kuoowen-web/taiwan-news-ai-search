# Deep Research System - Final Implementation Plan

## Executive Summary

Based on thorough codebase exploration and expert feedback, this plan implements a production-grade Deep Research reasoning system. The infrastructure is 100% complete - we only need to addÂ **LLM Prompts**Â and integrate three critical safeguards identified during pre-implementation review.

**Key Technical Decisions**:

1. âœ…Â **Unified Context Formatting**Â - Single Source of Truth in Orchestrator to prevent citation mismatch
2. âœ…Â **Token Budget Control**Â - Dynamic snippet truncation based on total char count
3. âœ…Â **Pydantic Validation**Â - Structured outputs with retry logic
4. âœ…Â **Graceful Degradation**Â - Strict mode fallback + continuous REJECT handling
5. âœ…Â **Hallucination Guards**Â - Writer sources verification against Analyst citations

---

## Critical Pre-Implementation Checks âš ï¸

### A. Formatted Context Length Control

**Problem Identified**: 50 articles Ã— 500 chars = 25,000 chars (~12-15k tokens) + prompt overhead could exceed context windows or inflate costs.

**Solution Implemented**: Add total token budget check inÂ `_format_context_shared()`:

```python
MAX_TOTAL_CHARS = 20000  # ~10k tokens budget
if total_length > MAX_TOTAL_CHARS:
    # Dynamically reduce snippet_length from 500 â†’ 300 or reduce item count
```

**Config Location**:Â `code/python/reasoning/orchestrator.py:_format_context_shared()`

---

### B. Writer sources_used Verification Logic

**Confirmed Correct**:

- âœ…Â `set([1]).issubset(set([1, 2]))`Â â†’ True (Writer can use subset of Analyst citations)
- âœ…Â `set([1, 2]).issubset(set([1]))`Â â†’ False (Writer adding new sources = hallucination, must block)

**Implementation**:Â `orchestrator.py:run_research()`Â line ~165

---

### C. ask_llm Compatibility Check

**Status**: âš ï¸Â **REQUIRES ATTENTION**

**Current Implementation**Â (`core/llm.py:157-246`):

- âœ…Â `ask_llm()`Â acceptsÂ `schema: Dict[str, Any]`Â parameter
- âœ… Routes to provider-specificÂ `get_completion(prompt, schema, ...)`
- âš ï¸Â **Anthropic provider**Â (`llm_providers/anthropic.py:90-129`):
    - UsesÂ **prompt engineering**Â for JSON enforcement (not tool use)
    - Schema injected into system message:Â `"You are a helpful assistant that always responds with valid JSON matching the provided schema."`
    - Uses regex to extract JSON from markdown fences:Â `re.search(r"(\{.*\})", cleaned, re.S)`

**âš ï¸ Risk**: No native Anthropic tool use or JSON mode enabled. Pydantic parse failures likely without prompt optimization.

**Mitigation Strategy**:

1. **Phase 1.1**: Test currentÂ `ask_llm()`Â with simple Agent prompt before full implementation
2. **Phase 1.2**: If failures occur, add explicit JSON format instructions to Agent prompts:
    
    ```
    Output ONLY valid JSON with no markdown fences. Do not include explanatory text.
    ```
    
3. **Phase 1.3**: Implement retry logic in BaseReasoningAgent (already exists with exponential backoff)

---

## Current Infrastructure Status (100% Complete)

### âœ… Fully Implemented

- **Orchestrator**Â (`reasoning/orchestrator.py`Â - 255 lines)
    
    - Actor-Critic loop with max 3 iterations
    - Phase 1: Source filtering by tier
    - Phase 2: Analyst â†’ Critic iteration
    - Phase 3: Writer final formatting
    - Phase 4: NLWeb Item result packaging
- **BaseReasoningAgent**Â (`reasoning/agents/base.py`Â - 113 lines)
    
    - `ask()`Â method with retry logic (max 3 attempts)
    - Exponential backoff (2^attempt seconds)
    - Timeout handling withÂ `asyncio.wait_for()`
    - Prompt template integration viaÂ `find_prompt()`Â andÂ `fill_prompt()`
- **SourceTierFilter**Â (`reasoning/filters/source_tier.py`Â - 164 lines)
    
    - Tier-based filtering (strict: 1-2, discovery: 1-5, monitor: compare 1 vs 5)
    - Content enrichment withÂ `[Tier X | type]`Â prefixes
    - NoValidSourcesError exception handling
- **TimeRangeExtractor**Â (`core/query_analysis/time_range_extractor.py`Â - 330+ lines)
    
    - 3-tier parsing: Regex â†’ LLM â†’ Keyword fallback
    - Returns absolute dates (`start_date`,Â `end_date`) for Stateless consistency
- **DeepResearchHandler**Â (`methods/deep_research.py`Â - 241 lines)
    
    - Inherits from NLWebHandler (reuses retrieval/ranking pipeline)
    - Mode detection (strict/discovery/monitor)
    - Temporal context packaging
    - Feature flag:Â `CONFIG.reasoning_params.enabled`

### ğŸ”„ Stub Implementations (Ready for Prompts)

- **AnalystAgent**Â - ReturnsÂ `{status: "DRAFT_READY", draft: "[STUB]", ...}`
- **CriticAgent**Â - ReturnsÂ `{status: "PASS"/"REJECT", critique: "[STUB]", ...}`
- **WriterAgent**Â - ReturnsÂ `{final_report: "[STUB]", sources_used: [...], ...}`

---

## Implementation Phases

### Phase 1: Core Agent Prompts (2 days)

#### 1.1 Pydantic Schemas (New File)

**Create**:Â `code/python/reasoning/schemas.py`

**Content**:

```python
from pydantic import BaseModel, Field, field_validator
from typing import List, Literal, Dict, Any

class AnalystResearchOutput(BaseModel):
    status: Literal["DRAFT_READY", "SEARCH_REQUIRED"]
    draft: str = Field(..., min_length=100)
    reasoning_chain: str
    citations_used: List[int] = Field(default_factory=list)  # [1, 3, 5]
    missing_information: List[str] = Field(default_factory=list)
    new_queries: List[str] = Field(default_factory=list)

    @field_validator('citations_used')
    @classmethod
    def validate_citations(cls, v):
        if not all(isinstance(x, int) and x > 0 for x in v):
            raise ValueError("Citation IDs must be positive integers")
        return v

class CriticReviewOutput(BaseModel):
    status: Literal["PASS", "WARN", "REJECT"]
    critique: str = Field(..., min_length=50)
    suggestions: List[str]
    mode_compliance: Literal["ç¬¦åˆ", "é•å"]
    logical_gaps: List[str] = Field(default_factory=list)
    source_issues: List[str] = Field(default_factory=list)

class WriterComposeOutput(BaseModel):
    final_report: str = Field(..., min_length=200)
    sources_used: List[int]  # Must be subset of Analyst citations
    confidence_level: Literal["High", "Medium", "Low"]
    methodology_note: str
```

---

#### 1.2 Orchestrator Unified Context Formatting

**Modify**:Â `code/python/reasoning/orchestrator.py`

**Add method**Â (beforeÂ `run_research()`):

```python
def _format_context_shared(self, items: List[Dict[str, Any]]) -> tuple[str, Dict[int, Dict]]:
    """
    Format context with citation markers - SINGLE SOURCE OF TRUTH.

    Returns:
        Tuple of (formatted_string, source_map)
    """
    MAX_TOTAL_CHARS = 20000  # âš ï¸ Token budget: ~10k tokens
    MAX_SNIPPET_LENGTH = 500
    source_map = {}
    formatted_parts = []

    # First pass: Calculate total length with max snippet size
    total_estimated = sum(min(len(item.get("description", "")), MAX_SNIPPET_LENGTH) for item in items[:50])

    # Adjust snippet length if over budget
    if total_estimated > MAX_TOTAL_CHARS:
        snippet_length = int(MAX_SNIPPET_LENGTH * (MAX_TOTAL_CHARS / total_estimated))
        self.logger.warning(f"Context too large, reducing snippet length to {snippet_length} chars")
    else:
        snippet_length = MAX_SNIPPET_LENGTH

    for idx, item in enumerate(items[:50], 1):
        source_map[idx] = item

        title = item.get("name", "No title")
        description = item.get("description", "")
        source = item.get("site", "Unknown")

        # Tier prefix already in description (from SourceTierFilter)
        snippet = description[:snippet_length] + ("..." if len(description) > snippet_length else "")

        formatted_parts.append(f"[{idx}] {source} - {title}\n{snippet}\n")

    formatted_string = "\n".join(formatted_parts)
    self.logger.info(f"Formatted context: {len(source_map)} sources, {len(formatted_string)} chars")

    return formatted_string, source_map
```

**Modify**Â `run_research()`Â method:

```python
async def run_research(...) -> List[Dict[str, Any]]:
    """Execute deep research using Actor-Critic loop."""
    try:
        # Phase 1: Filter context
        current_context = self.source_filter.filter_and_enrich(items, mode)

        # âš ï¸ NEW: Unified context formatting (Single Source of Truth)
        self.formatted_context, self.source_map = self._format_context_shared(current_context)

        # Phase 2: Actor-Critic Loop
        iteration = 0
        draft = None
        review = None
        reject_count = 0

        while iteration < max_iterations:
            # Analyst
            if review and review.status == "REJECT":
                reject_count += 1
                response = await self.analyst.revise(
                    draft=draft,
                    review=review,
                    formatted_context=self.formatted_context  # âš ï¸ Pass unified context
                )
            else:
                response = await self.analyst.research(
                    query=query,
                    formatted_context=self.formatted_context,  # âš ï¸ Pass unified context
                    mode=mode,
                    temporal_context=temporal_context
                )

            draft = response.draft

            # Critic
            review = await self.critic.review(draft, query, mode)

            # Check convergence
            if review.status in ["PASS", "WARN"]:
                break

            iteration += 1

        # âš ï¸ Graceful degradation check
        if reject_count >= max_iterations and review.status == "REJECT":
            self.logger.warning(f"Max iterations with continuous REJECTs. Degrading gracefully.")
            review.critique = f"[è­¦å‘Š] ç¶“é {max_iterations} è¼ªä¿®è¨‚ä»ç„¡æ³•å®Œå…¨è§£æ±ºå•é¡Œã€‚\n\n{review.critique}"

        # Phase 3: Writer
        final_report = await self.writer.compose(
            draft=draft,
            review=review,
            formatted_context=self.formatted_context,  # âš ï¸ Pass unified context
            analyst_citations=response.citations_used,
            mode=mode
        )

        # âš ï¸ Hallucination Guard: Verify Writer sources âŠ† Analyst citations
        if not set(final_report.sources_used).issubset(set(response.citations_used)):
            self.logger.error(f"Writer hallucination: {final_report.sources_used} not subset of {response.citations_used}")
            final_report.sources_used = list(set(final_report.sources_used) & set(response.citations_used))
            final_report.confidence_level = "Low"

        # ... rest of existing code ...
```

---

#### 1.3 SourceTierFilter Graceful Fallback

**Modify**:Â `code/python/reasoning/filters/source_tier.py`

**Update**Â `filter_and_enrich()`Â method (around line 66):

```python
# Check for empty result in strict mode
if mode == "strict" and not filtered_items:
    self.logger.warning(f"Strict mode filtered out all sources! Falling back to Discovery.")

    # âš ï¸ Retry with discovery mode (max_tier=5)
    for item in items:
        source = item.get("site", "").strip()
        tier_info = self._get_tier_info(source)
        tier = tier_info["tier"]
        source_type = tier_info["type"]

        if tier <= 5:
            enriched_item = self._enrich_item(item, tier, source_type, source)
            # Add fallback warning to metadata
            if "_reasoning_metadata" not in enriched_item:
                enriched_item["_reasoning_metadata"] = {}
            enriched_item["_reasoning_metadata"]["fallback_warning"] = (
                "åŸå§‹ç‚º Strict æ¨¡å¼ï¼Œä½†éæ¿¾å¾Œç„¡ä¾†æºï¼Œå·²è‡ªå‹•åˆ‡æ›ç‚º Discovery æ¨¡å¼"
            )
            filtered_items.append(enriched_item)

    if not filtered_items:
        raise NoValidSourcesError("No valid sources available in any mode")

return filtered_items
```

---

#### 1.4 BaseReasoningAgent Enhancement

**Modify**:Â `code/python/reasoning/agents/base.py`

**Add new method**Â (afterÂ `ask()`):

```python
async def call_llm_validated(
    self,
    prompt: str,
    response_schema: Type[BaseModel],
    level: str = "high"
) -> BaseModel:
    """
    Call LLM with Pydantic validation.

    Args:
        prompt: Direct prompt string (not template name)
        response_schema: Pydantic model for validation
        level: LLM quality level

    Returns:
        Validated Pydantic model instance

    Raises:
        ValidationError: If max retries exceeded
    """
    from pydantic import ValidationError

    for attempt in range(self.max_retries):
        try:
            # Call LLM
            response = await asyncio.wait_for(
                ask_llm(
                    prompt,
                    schema={},  # Schema enforcement via Pydantic post-validation
                    level=level,
                    query_params=self.handler.query_params
                ),
                timeout=self.timeout
            )

            # Parse and validate
            if isinstance(response, dict):
                validated = response_schema.model_validate(response)
            else:
                validated = response_schema.model_validate_json(response)

            self.logger.info(f"LLM response validated against {response_schema.__name__}")
            return validated

        except ValidationError as e:
            self.logger.warning(f"Validation failed (attempt {attempt+1}/{self.max_retries}): {e}")
            if attempt == self.max_retries - 1:
                raise
            await asyncio.sleep(2 ** attempt)

        except asyncio.TimeoutError:
            self.logger.error(f"LLM call timed out after {self.timeout}s")
            raise TimeoutError(f"LLM call timed out")

    raise ValueError(f"Max retries exceeded for {response_schema.__name__}")
```

---

#### 1.5 Analyst Agent Prompts

**Modify**:Â `code/python/reasoning/agents/analyst.py`

**Replace**Â `research()`Â method:

```python
from reasoning.schemas import AnalystResearchOutput

async def research(
    self,
    query: str,
    formatted_context: str,  # âš ï¸ Unified context string
    mode: str,
    temporal_context: Optional[Dict[str, Any]] = None
) -> AnalystResearchOutput:
    """Conduct research and generate initial draft."""

    mode_instructions = {
        "strict": "ä½¿ç”¨ä¿å®ˆæ¨ç†ï¼Œåƒ…å¼•ç”¨ Tier 1-2 ä¾†æºã€‚é¿å…æ¨æ¸¬ã€‚",
        "discovery": "å…¨é¢åˆ†ææ‰€æœ‰ä¾†æºï¼Œæ¨™è¨» Tier 3-5 ä¾†æºä¸¦åŠ è­¦èªã€‚",
        "monitor": "æ¯”å° Tier 1ï¼ˆå®˜æ–¹ï¼‰èˆ‡ Tier 5ï¼ˆç¤¾ç¾¤ï¼‰çš„è½å·®ã€‚"
    }

    temporal_instruction = ""
    if temporal_context and temporal_context.get('is_temporal_query'):
        temporal_instruction = f"\nâ° æ™‚é–“ç¯„åœ: {temporal_context['start_date']} è‡³ {temporal_context['end_date']}"

    prompt = f"""ä½ æ˜¯å°ˆæ¥­ç ”ç©¶åˆ†æå¸«ï¼ˆAnalyst Agentï¼‰ã€‚è«‹åŸºæ–¼ä¾†æºé€²è¡Œæ·±åº¦ç ”ç©¶ã€‚

## ä½¿ç”¨è€…æŸ¥è©¢
{query}

## ç ”ç©¶æ¨¡å¼
{mode.upper()} - {mode_instructions[mode]}
{temporal_instruction}

## å¯ç”¨ä¾†æºï¼ˆå·²æ¨™è¨»å¯ä¿¡åº¦ï¼‰
{formatted_context}

## è¼¸å‡ºè¦æ±‚ï¼ˆJSON æ ¼å¼ï¼Œç„¡ markdown æ¨™è¨˜ï¼‰
{{
  "status": "DRAFT_READY",
  "draft": "ç ”ç©¶è‰ç¨¿ï¼ˆMarkdownï¼‰",
  "reasoning_chain": "æ¨ç†éç¨‹",
  "citations_used": [1, 3, 5],
  "missing_information": ["åƒ…åˆ—å‡ºé˜»ç¤™çµè«–çš„é—œéµç¼ºå¤±"],
  "new_queries": []
}}

## Draft æ ¼å¼
### æ ¸å¿ƒç™¼ç¾
- [1] å°ç©é›»å®£å¸ƒ...
- [3] åˆ†æå¸«èªç‚º...

### é‚è¼¯æ¨è«–
åŸºæ–¼ [1], [3]ï¼Œå¯æ¨è«–...
**æ¨ç†é¡å‹**: æ¼”ç¹¹/æ­¸ç´/æº¯å› 

## å¼•ç”¨è¦å‰‡
- ä½¿ç”¨ [æ•¸å­—] æ ¼å¼æ¨™è¨»ä¾†æº
- æ¯å€‹äº‹å¯¦å¿…é ˆæ¨™è¨»ä¾†æº
- Missing Information åƒ…åˆ—å‡ºã€Œé—œéµç¼ºå¤±ã€ï¼ˆé˜»ç¤™çµè«–çš„è³‡è¨Šï¼‰

è¼¸å‡ºç´” JSONï¼Œä¸è¦åŒ…å«ä»»ä½•è§£é‡‹æ–‡å­—æˆ– markdown æ¨™è¨˜ã€‚"""

    return await self.call_llm_validated(
        prompt=prompt,
        response_schema=AnalystResearchOutput,
        level="high"
    )
```

**Replace**Â `revise()`Â method:

```python
async def revise(
    self,
    draft: str,
    review: CriticReviewOutput,
    formatted_context: str
) -> AnalystResearchOutput:
    """Revise draft based on critique."""

    prompt = f"""ä½ æ˜¯å°ˆæ¥­ç ”ç©¶åˆ†æå¸«ã€‚è«‹æ ¹æ“šè©•è«–å®¶åé¥‹ä¿®è¨‚è‰ç¨¿ã€‚

## åŸå§‹è‰ç¨¿
{draft}

## è©•è«–å®¶åé¥‹
- ç‹€æ…‹: {review.status}
- è©•è«–: {review.critique}
- å»ºè­°: {', '.join(review.suggestions)}
- é‚è¼¯ç¼ºå£: {', '.join(review.logical_gaps)}

## å¯ç”¨ä¾†æº
{formatted_context}

## è¼¸å‡ºè¦æ±‚ï¼ˆJSON æ ¼å¼ï¼‰
{{
  "status": "DRAFT_READY",
  "draft": "ä¿®è¨‚å¾Œçš„è‰ç¨¿",
  "reasoning_chain": "ä¿®è¨‚æ¨ç†",
  "citations_used": [1, 2, 5],
  "missing_information": [],
  "changes_made": ["ä¿®æ­£å› æœé—œä¿‚", "è£œå……ä¾†æºå¼•ç”¨"]
}}

è¼¸å‡ºç´” JSONï¼Œä¸è¦åŒ…å« markdown æ¨™è¨˜ã€‚"""

    return await self.call_llm_validated(
        prompt=prompt,
        response_schema=AnalystResearchOutput,
        level="high"
    )
```

---

#### 1.6 Critic Agent Prompts

**Modify**:Â `code/python/reasoning/agents/critic.py`

**Replace**Â `review()`Â method:

```python
from reasoning.schemas import CriticReviewOutput

async def review(
    self,
    draft: str,
    query: str,
    mode: str
) -> CriticReviewOutput:
    """Review draft for quality and compliance."""

    mode_rules = {
        "strict": "åƒ…å…è¨± Tier 1-2ã€‚å¼•ç”¨ Tier 3-5 â†’ é•å",
        "discovery": "å…è¨± Tier 3-5ï¼Œä½†å¿…é ˆåŠ è¨»è­¦èª",
        "monitor": "å¿…é ˆæ¯”å° Tier 1 vs Tier 5 å·®ç•°"
    }

    prompt = f"""ä½ æ˜¯å°ˆæ¥­è©•è«–å®¶ï¼ˆCritic Agentï¼‰ã€‚è«‹å¯©æŸ¥è‰ç¨¿é‚è¼¯èˆ‡ä¾†æºåˆè¦æ€§ã€‚

## æŸ¥è©¢
{query}

## æ¨¡å¼è¦å‰‡
{mode.upper()} - {mode_rules[mode]}

## å¾…å¯©æŸ¥è‰ç¨¿
{draft}

## å¯©æŸ¥æ¸…å–®
1. **æ¼”ç¹¹æ¨ç†**: å¤§å‰ææ˜¯å¦é©ç”¨ï¼Ÿ
2. **æ­¸ç´æ¨ç†**: æ¨£æœ¬æ•¸è¶³å¤ ï¼Ÿä»£è¡¨æ€§ï¼Ÿ
3. **æº¯å› æ¨ç†**: æ˜¯å¦è€ƒæ…®æ›¿ä»£è§£é‡‹ï¼Ÿ
4. **ä¾†æºåˆè¦**: æ˜¯å¦ç¬¦åˆ {mode} è¦å‰‡ï¼Ÿ
5. **å› æœè¬¬èª¤**: æ˜¯å¦æ··æ·†ç›¸é—œæ€§èˆ‡å› æœæ€§ï¼Ÿ

## è¼¸å‡ºè¦æ±‚ï¼ˆJSON æ ¼å¼ï¼‰
{{
  "status": "PASS",  // PASS / WARN / REJECT
  "critique": "è©³ç´°å¯©æŸ¥æ„è¦‹",
  "suggestions": ["å»ºè­°1", "å»ºè­°2"],
  "mode_compliance": "ç¬¦åˆ",  // ç¬¦åˆ / é•å
  "logical_gaps": ["é‚è¼¯ç¼ºå£"],
  "source_issues": ["ä¾†æºå•é¡Œ"]
}}

è¼¸å‡ºç´” JSONã€‚"""

    return await self.call_llm_validated(
        prompt=prompt,
        response_schema=CriticReviewOutput,
        level="high"
    )
```

---

#### 1.7 Writer Agent Prompts

**Modify**:Â `code/python/reasoning/agents/writer.py`

**Replace**Â `compose()`Â method:

```python
from reasoning.schemas import WriterComposeOutput, CriticReviewOutput

async def compose(
    self,
    draft: str,
    review: CriticReviewOutput,
    formatted_context: str,
    analyst_citations: List[int],
    mode: str
) -> WriterComposeOutput:
    """Compose final report."""

    confidence_map = {"PASS": "High", "WARN": "Medium", "REJECT": "Low"}
    suggested_confidence = confidence_map.get(review.status, "Medium")

    prompt = f"""ä½ æ˜¯å°ˆæ¥­å ±å‘Šç·¨è¼¯ï¼ˆWriter Agentï¼‰ã€‚è«‹æ•´ç†è‰ç¨¿ç‚ºæœ€çµ‚å ±å‘Šã€‚

## è‰ç¨¿
{draft}

## è©•è«–å®¶è©•åƒ¹
{review.status} - {review.critique}

## Analyst å·²å¼•ç”¨ä¾†æº ID
{analyst_citations}

## å¯ç”¨ä¾†æº
{formatted_context}

## è¼¸å‡ºè¦æ±‚ï¼ˆJSON æ ¼å¼ï¼‰
{{
  "final_report": "# ç ”ç©¶å ±å‘Š\\n\\n## æ ¸å¿ƒç™¼ç¾\\n- [1] ...\\n\\n## æ·±åº¦åˆ†æ\\n...\\n\\n## è³‡æ–™ä¾†æº\\n...",
  "sources_used": [1, 3, 5],  // âš ï¸ å¿…é ˆæ˜¯ analyst_citations çš„å­é›†
  "confidence_level": "{suggested_confidence}",
  "methodology_note": "ä½¿ç”¨ {mode.upper()} æ¨¡å¼ï¼Œç¶“é X è¼ªè¿­ä»£"
}}

## ç·¨è¼¯åŸå‰‡
1. æ–‡ç« åŒ–æ½¤é£¾
2. ä¿ç•™æ‰€æœ‰ [æ•¸å­—] å¼•ç”¨
3. åƒ…ä½¿ç”¨ draft ä¸­è³‡è¨Šï¼ˆä¸å¾—å¹»è¦ºï¼‰
4. sources_used å¿…é ˆ âŠ† analyst_citationsï¼ˆå¦å‰‡å¹»è¦ºï¼ï¼‰

è¼¸å‡ºç´” JSONã€‚"""

    return await self.call_llm_validated(
        prompt=prompt,
        response_schema=WriterComposeOutput,
        level="high"
    )
```

---

### Phase 2: Progressive Display (1 day)

#### 2.1 Backend SSE Streaming

**Modify**:Â `code/python/reasoning/orchestrator.py`

**Add wrapper**Â (top ofÂ `run_research()`):

```python
async def safe_send_progress(message: Dict):
    """Non-blocking progress sender."""
    try:
        await self.handler.send_message(message)
    except Exception as e:
        self.logger.warning(f"Progress message failed: {e}")
```

**Add progress messages**Â (in loop):

```python
while iteration < max_iterations:
    # Analyst start
    await safe_send_progress({
        "message_type": "intermediate_result",
        "stage": "analyst_analyzing",
        "iteration": iteration + 1,
        "total_iterations": max_iterations
    })

    # ... Analyst call ...

    # Analyst complete
    await safe_send_progress({
        "message_type": "intermediate_result",
        "stage": "analyst_draft_ready",
        "citations_count": len(response.citations_used)
    })

    # Critic start
    await safe_send_progress({
        "message_type": "intermediate_result",
        "stage": "critic_reviewing"
    })

    # ... Critic call ...

    # Critic complete
    await safe_send_progress({
        "message_type": "intermediate_result",
        "stage": "critic_review_complete",
        "status": review.status,
        "critique_preview": review.critique[:150] + "..."
    })
```

#### 2.2 Frontend Display

**Modify**:Â `static/news-search-prototype.html`

**Add to**Â `handleStreamingRequest()`Â switch:

```javascript
case 'intermediate_result':
    this.updateProgressDisplay(data);
    break;
```

**Add method**:

```javascript
updateProgressDisplay(data) {
    let container = document.getElementById('deep-research-progress');

    if (!container) {
        container = document.createElement('div');
        container.id = 'deep-research-progress';
        container.innerHTML = `
            <div class="progress-timeline">
                <div class="progress-step" data-stage="analyst">
                    <span class="step-icon">ğŸ“Š</span>
                    <span class="step-label">åˆ†æä¸­</span>
                </div>
                <div class="progress-arrow">â†’</div>
                <div class="progress-step" data-stage="critic">
                    <span class="step-icon">ğŸ”</span>
                    <span class="step-label">å¯©æŸ¥ä¸­</span>
                </div>
                <div class="progress-arrow">â†’</div>
                <div class="progress-step" data-stage="writer">
                    <span class="step-icon">âœï¸</span>
                    <span class="step-label">æ’°å¯«å ±å‘Š</span>
                </div>
            </div>
            <div class="progress-details"></div>
        `;
        document.querySelector('.results-area').prepend(container);
    }

    const stage = data.stage;
    const details = container.querySelector('.progress-details');

    if (stage.includes('analyst')) {
        const step = container.querySelector('[data-stage="analyst"]');
        step.classList.add('active');
        if (stage === 'analyst_draft_ready') {
            step.classList.remove('active');
            step.classList.add('complete');
            details.textContent = `âœ… å·²å¼•ç”¨ ${data.citations_count} å€‹ä¾†æº`;
        }
    } else if (stage.includes('critic')) {
        const step = container.querySelector('[data-stage="critic"]');
        step.classList.add('active');
        if (stage === 'critic_review_complete') {
            step.classList.remove('active');
            step.classList.add('complete');
            const emoji = data.status === 'PASS' ? 'âœ…' : data.status === 'WARN' ? 'âš ï¸' : 'âŒ';
            details.textContent = `${emoji} ${data.status}`;
        }
    } else if (stage === 'writer_composing') {
        const step = container.querySelector('[data-stage="writer"]');
        step.classList.add('active');
    }
}
```

**Add CSS**:

```css
.deep-research-progress {
    background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
    border-radius: 12px;
    padding: 25px;
    margin-bottom: 20px;
}

.progress-step {
    opacity: 0.4;
    transition: opacity 0.3s;
}

.progress-step.active {
    opacity: 1;
    animation: pulse 1.5s infinite;
    will-change: transform;  /* âš ï¸ Performance optimization */
}

.progress-step.complete {
    opacity: 1;
}

@keyframes pulse {
    0%, 100% { transform: scale(1); }
    50% { transform: scale(1.1); }
}
```

---

### Phase 3: Mode Selection UI (0.5 day)

#### 3.1 Frontend Mode Selector

**Modify**:Â `static/news-search-prototype.html`

**Add UI**Â (around line 1042):

```html
<div class="research-mode-selector">
    <label>ğŸ”§ ç ”ç©¶æ¨¡å¼</label>
    <div class="mode-options">
        <button class="mode-option" data-mode="discovery" data-active="true">
            <span class="mode-icon">ğŸ”</span>
            <div>
                <div class="mode-label">å»£æ³›æ¢ç´¢</div>
                <div class="mode-desc">åŒ…å«ç¤¾ç¾¤/è«–å£‡ (Tier 1-5)</div>
            </div>
        </button>
        <button class="mode-option" data-mode="strict">
            <span class="mode-icon">âœ“</span>
            <div>
                <div class="mode-label">åš´è¬¹æŸ¥æ ¸</div>
                <div class="mode-desc">åƒ…å®˜æ–¹/æ¬Šå¨ (Tier 1-2)</div>
            </div>
        </button>
        <button class="mode-option" data-mode="monitor">
            <span class="mode-icon">ğŸ“Š</span>
            <div>
                <div class="mode-label">æƒ…å ±ç›£æ¸¬</div>
                <div class="mode-desc">æ¯”å°å®˜æ–¹èˆ‡æ°‘é–“è½å·®</div>
            </div>
        </button>
    </div>
</div>

<script>
document.querySelectorAll('.mode-option').forEach(btn => {
    btn.addEventListener('click', function() {
        document.querySelectorAll('.mode-option').forEach(b => b.dataset.active = "false");
        this.dataset.active = "true";
        window.currentResearchMode = this.dataset.mode;
    });
});
window.currentResearchMode = 'discovery';
</script>
```

#### 3.2 Backend Parameter Reading

**Modify**:Â `code/python/methods/deep_research.py`

**Update**Â `_detect_research_mode()`:

```python
async def _detect_research_mode(self) -> str:
    """Detect research mode."""
    # âš ï¸ Priority 1: User UI selection
    if 'research_mode' in self.query_params:
        user_mode = self.query_params['research_mode']
        if user_mode in ['strict', 'discovery', 'monitor']:
            logger.info(f"Using user-selected mode: {user_mode}")
            return user_mode

    # Priority 2: Keyword detection (existing code)
    query = self.query.lower()

    if any(kw in query for kw in ['verify', 'æŸ¥è­‰', 'é©—è­‰']):
        return 'strict'

    if any(kw in query for kw in ['trend', 'è¶¨å‹¢', 'è¼¿æƒ…']):
        return 'monitor'

    return 'discovery'
```

**Frontend sending**:

```javascript
function sendQuery() {
    const requestData = {
        query: document.getElementById('search-input').value,
        generate_mode: 'deep_research',
        research_mode: window.currentResearchMode || 'discovery',  // âš ï¸ NEW
        // ... other params ...
    };
    // ... fetch logic ...
}
```

---

## Critical Files to Modify

### New Files (1)

1. âœ…Â `code/python/reasoning/schemas.py`Â (~150 lines) - Pydantic models

### Modified Files (8)

2. âœ…Â `code/python/reasoning/orchestrator.py`Â - AddÂ `_format_context_shared()`, updateÂ `run_research()`
3. âœ…Â `code/python/reasoning/filters/source_tier.py`Â - Add graceful fallback
4. âœ…Â `code/python/reasoning/agents/base.py`Â - AddÂ `call_llm_validated()`
5. âœ…Â `code/python/reasoning/agents/analyst.py`Â - ReplaceÂ `research()`Â andÂ `revise()`
6. âœ…Â `code/python/reasoning/agents/critic.py`Â - ReplaceÂ `review()`
7. âœ…Â `code/python/reasoning/agents/writer.py`Â - ReplaceÂ `compose()`
8. âœ…Â `static/news-search-prototype.html`Â - Add progress display + mode selector
9. âœ…Â `code/python/methods/deep_research.py`Â - UpdateÂ `_detect_research_mode()`

---

## Implementation Sequence

### Day 1 (Phase 1.1-1.4)

1. CreateÂ `reasoning/schemas.py`
2. ModifyÂ `orchestrator.py`Â - AddÂ `_format_context_shared()`
3. ModifyÂ `source_tier.py`Â - Add fallback
4. ModifyÂ `base.py`Â - AddÂ `call_llm_validated()`
5. **TEST**: Run simple LLM call to verifyÂ `ask_llm()`Â compatibility

### Day 2 (Phase 1.5-1.7)

6. ModifyÂ `analyst.py`Â - Add prompts
7. ModifyÂ `critic.py`Â - Add prompts
8. ModifyÂ `writer.py`Â - Add prompts
9. **TEST**: End-to-end Deep Research query

### Day 3 (Phase 2)

10. ModifyÂ `orchestrator.py`Â - Add SSE progress messages
11. ModifyÂ `news-search-prototype.html`Â - Add progress display UI
12. **TEST**: Verify progress updates during execution

### Day 4 (Phase 3)

13. ModifyÂ `news-search-prototype.html`Â - Add mode selector
14. ModifyÂ `deep_research.py`Â - ReadÂ `research_mode`Â parameter
15. **TEST**: Verify mode selection affects source filtering

---

## Testing Checklist

### Phase 1 Tests

- [ ] Â Pydantic schemas validate correct JSON
- [ ] Â Pydantic schemas reject malformed JSON
- [ ] Â Context formatting respects 20k char limit
- [ ] Â Citation markers [1], [2], [3] consistent across agents
- [ ] Â Writer sources_used âŠ† Analyst citations_used
- [ ] Â Strict mode fallback to Discovery when no sources
- [ ] Â Continuous REJECT (3x) triggers graceful degradation

### Phase 2 Tests

- [ ] Â Progress messages appear in frontend
- [ ] Â Progress doesn't block Agent execution
- [ ] Â Iteration count displays correctly (1/3, 2/3, 3/3)

### Phase 3 Tests

- [ ] Â Mode selector UI displays correctly
- [ ] Â Selected mode sent to backend
- [ ] Â Strict mode filters Tier 3-5 sources
- [ ] Â Discovery mode allows all tiers
- [ ] Â Monitor mode Critic checks Tier 1 vs 5 comparison

---

## Risk Mitigation

### Risk 1: ask_llm JSON Parse Failures

**Mitigation**:

- Add explicit JSON format instructions to prompts
- Use regex cleanup inÂ `call_llm_validated()`
- Retry mechanism (3 attempts with exponential backoff)

### Risk 2: Token Cost Explosion

**Mitigation**:

- 20k char budget enforced
- Dynamic snippet truncation
- Monitor via analytics logs

### Risk 3: Writer Hallucination

**Mitigation**:

- Assert check:Â `sources_used âŠ† analyst_citations`
- Automatic correction if violated
- Confidence levelé™ç‚º Low

---

## Success Criteria

### Phase 1

- [ ] Â Analyst generates draft with citation markers [1], [2], [3]
- [ ] Â Critic detects logical fallacies and mode violations
- [ ] Â Writer produces structured Markdown report
- [ ] Â All outputs pass Pydantic validation
- [ ] Â Context stays under 20k chars

### Phase 2

- [ ] Â Users see real-time progress updates
- [ ] Â SSE doesn't impact latency

### Phase 3

- [ ] Â Users can select modes
- [ ] Â Mode selection correctly filters sources

---

## Next Steps After Implementation

1. **Collect Real Usage Data**Â (Week 5-7)
    
    - Monitor iteration counts
    - Track REJECT rates
    - Measure token costs
2. **Optimize Prompts**Â (Week 8)
    
    - Reduce REJECT rates through prompt tuning
    - Shorten prompts where possible
3. **Phase 4: Clarification System**Â (Week 9-10)
    
    - Implement Clarification Agent
    - Add frontend Dialog UI
    - Stateless clarification flow
4. **Phase 5: Gap Detection**Â (Week 11-12)
    
    - ImplementÂ `SEARCH_REQUIRED`Â handling
    - Add secondary search capability