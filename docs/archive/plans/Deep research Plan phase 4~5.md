## Phase 4: Clarification System

### Use Case 1: Pre-Search Clarification (NEW)

**Trigger**: Python time parser fails OR query is ambiguous

**Location**:Â `code/python/methods/deep_research.py`Â before calling orchestrator

**Implementation**:

1. **Create Clarification Agent**Â (`code/python/reasoning/agents/clarification.py`):
    
    ```python
    class ClarificationAgent(BaseReasoningAgent):
        async def generate_options(self, query: str, ambiguity_type: str) -> dict:
            # Calls LLM with clarification prompt from PDF
            # Returns JSON with options for user selection
    ```
    
2. **Add Pre-Check in Deep Research Handler**Â (`code/python/methods/deep_research.py:execute_deep_research()`):
    
    ```python
    # Before orchestrator.run_research():
    # 1. Check if time_parser failed
    # 2. If failed, call ClarificationAgent
    # 3. Send SSE message: message_type="clarification_required"
    # 4. Return early (don't continue to research)
    # Frontend will show modal and re-submit with clarified params
    ```
    
3. **Frontend Clarification Modal**Â (`static/news-search-prototype.html`):
    
    - Add HTML structure for clarification modal
    - Add SSE handler forÂ `message_type: 'clarification_required'`
    - Display options from backend
    - On user selection, re-submit query with clarified parameters

**Flow**:

```
User Query â†’ Time Parser Fails â†’ ClarificationAgent.generate_options()
  â†’ Send SSE "clarification_required" â†’ Frontend Shows Modal
  â†’ User Selects Option â†’ Re-submit Query â†’ Research Proceeds
```

---

### Use Case 2: Mid-Research Gap Detection (Phase 5)

**Trigger**: Analyst returnsÂ `status: "SEARCH_REQUIRED"`

**Location**: Replace TODO atÂ `code/python/reasoning/orchestrator.py:284`

**Implementation**: Implement secondary search flow per PDF spec (Page 3-4)

---

## Phase 5: Gap Detection & Secondary Search

### Core Implementation

**File**:Â `code/python/reasoning/orchestrator.py`

**Replace lines 284-307**Â with:

```python
# Gap detection: Handle SEARCH_REQUIRED
if response.status == "SEARCH_REQUIRED":
    self.logger.warning(
        f"Analyst requested additional search (iteration {iteration + 1}): "
        f"{response.new_queries}"
    )

    # Send progress message to frontend
    await self._send_progress({
        "message_type": "intermediate_result",
        "stage": "gap_search_started",
        "gap_reason": response.reasoning_gap,
        "new_queries": response.new_queries,
        "iteration": iteration + 1
    })

    # Execute secondary search for each new query
    from core.retriever import search
    secondary_results = []

    for new_query in response.new_queries:
        try:
            # Call retriever with same parameters as original search
            results = await search(
                query=new_query,
                site=self.handler.site,
                num_results=20,  # Smaller batch for gap search
                query_params=self.handler.query_params
            )
            secondary_results.extend(results)
            self.logger.info(f"Gap search for '{new_query}': {len(results)} results")
        except Exception as e:
            self.logger.error(f"Secondary search failed for '{new_query}': {e}")

    # Handle search results
    if secondary_results:
        # Filter and enrich new results
        new_context = self.source_filter.filter_and_enrich(secondary_results, mode)

        # Merge with existing context
        current_context.extend(new_context)
        self.logger.info(f"Added {len(new_context)} sources from secondary search")

        # Re-format unified context with updated citations
        self.formatted_context, self.source_map = self._format_context_shared(current_context)

        # Continue to next iteration (Analyst will retry with expanded context)
        iteration += 1
        continue
    else:
        # No results found - force Analyst to work with existing data
        self.logger.warning("Secondary search returned no results")

        # Add system hint to context
        system_hint = "\n\n[ç³»çµ±æç¤º] é‡å°ç¼ºå£çš„è£œå……æœå°‹æœªç™¼ç¾æœ‰æ•ˆçµæœï¼Œè«‹åŸºæ–¼ç¾æœ‰è³‡è¨Šæ¨è«–ã€‚"
        self.formatted_context += system_hint

        # Increment iteration and let Critic review whatever Analyst produces
        iteration += 1
        # Do NOT continue - let it proceed to Critic evaluation
```

### Frontend Progress Display

**File**:Â `static/news-search-prototype.html`

**Add to SSE handler**Â (inÂ `handleStreamingRequest()`Â around line 1674):

```javascript
case 'gap_search_started':
    this.updateReasoningProgress({
        stage: 'gap_search',
        reason: data.gap_reason,
        queries: data.new_queries
    });
    break;
```

**Update Progress Display**Â (inÂ `updateReasoningProgress()`Â around line 1742):

```javascript
else if (stage === 'gap_search') {
    const details = container.querySelector('.progress-details');
    if (details) {
        details.innerHTML = `
            <div style="color: #f59e0b; font-weight: 500;">ğŸ” æ­£åœ¨è£œå……æœå°‹...</div>
            <div style="font-size: 11px; margin-top: 4px; color: #64748b;">
                ${data.reason || 'ç™¼ç¾è³‡è¨Šç¼ºå£'}
            </div>
        `;
    }
}
```

---

## Configuration Changes

**File**:Â `config/config_retrieval.yaml`

Add parameters for gap search control:

```yaml
reasoning_params:
  enabled: true
  max_iterations: 3  # Includes gap search iterations
  max_gap_searches: 1  # Max secondary searches per query (built into max_iterations)
  gap_search_num_results: 20  # Smaller batch for targeted gap filling
  analyst_timeout: 60
  critic_timeout: 30
  writer_timeout: 45
```

---

## Key Design Decisions (Based on PDF)

### 1. Context Merging Strategy

**Choice**:Â **Append merge**Â (ä¿ç•™åŸå§‹çµæœ)

```python
current_context.extend(new_context)  # Append, not replace
```

**Rationale**: PDF spec (Page 4, line 66) usesÂ `current_context += ...`

### 2. Error Handling

**Choice**:Â **Force Analyst to produce with system hint**

When secondary search fails:

- Add system message to context
- Don't return error to user
- Let Critic evaluate the "best effort" output

**Rationale**: PDF spec (Page 4, lines 79-84) - avoid dead loops

### 3. Iteration Limit

**Choice**:Â **MAX_ITERATIONS = 3**Â (includes gap searches)

EachÂ `SEARCH_REQUIRED`Â consumes one iteration:

- Iteration 1: Analyst returns SEARCH_REQUIRED â†’ gap search â†’ retry
- Iteration 2: Analyst returns DRAFT_READY â†’ Critic reviews
- Iteration 3: If still REJECT, graceful degradation

**Rationale**: PDF spec (Page 1, line 41, Page 5, lines 93-102)

### 4. Clarification Flow

**Choice**:Â **Two separate mechanisms**

1. **Pre-Search**: Needs user interaction (modal)
2. **Mid-Research**: Automatic (no user interaction)

**Rationale**: PDF clearly separates these (Page 2 vs Page 3-4)

---

## Implementation Checklist

### Phase 5: Gap Detection (Priority 1)

- [ ] Â Replace TODO inÂ `orchestrator.py:284-307`Â with secondary search logic
- [ ] Â ImportÂ `search`Â fromÂ `core.retriever`
- [ ] Â Add SSE progress message forÂ `gap_search_started`
- [ ] Â Add frontend SSE handler for gap search progress
- [ ] Â UpdateÂ `updateReasoningProgress()`Â to show gap search stage
- [ ] Â Add config parameters toÂ `config_retrieval.yaml`
- [ ] Â Test with queries that trigger SEARCH_REQUIRED

### Phase 4: Clarification Agent (Priority 2)

- [ ] Â CreateÂ `code/python/reasoning/agents/clarification.py`
- [ ] Â ImplementÂ `ClarificationAgent`Â class with PDF prompt (Page 23-26)
- [ ] Â Add pre-check inÂ `deep_research.py:execute_deep_research()`
- [ ] Â Send SSEÂ `clarification_required`Â message
- [ ] Â Add frontend clarification modal HTML
- [ ] Â Add SSE handler for clarification
- [ ] Â Add JavaScript for option selection and re-submission
- [ ] Â Test with ambiguous queries (e.g., "è”¡è‹±æ–‡çš„å…©å²¸æ”¿ç­–")

---

## Files to Modify

### Backend (3 files)

1. **`code/python/reasoning/orchestrator.py`**Â (lines 278-307)
    
    - Replace TODO with secondary search implementation
    - ImportÂ `search`Â fromÂ `core.retriever`
2. **`code/python/reasoning/agents/clarification.py`**Â (NEW)
    
    - Create ClarificationAgent class
    - Implement prompt from PDF Page 23-26
3. **`code/python/methods/deep_research.py`**Â (add pre-check)
    
    - BeforeÂ `orchestrator.run_research()`, check time_parser
    - Call ClarificationAgent if needed
    - Send SSE clarification message

### Frontend (1 file)

4. **`static/news-search-prototype.html`**
    - Add clarification modal HTML (after line 1316)
    - Add SSE handler cases (around line 1674)
    - UpdateÂ `updateReasoningProgress()`Â (around line 1742)
    - Add clarification modal JavaScript handlers

### Configuration (1 file)

5. **`config/config_retrieval.yaml`**
    - Add gap search parameters

---

## Testing Strategy

### Phase 5 Testing

**Test Case 1: Successful Gap Search**

- Query: "å°ç©é›»é«˜é›„å» å»¶å¾ŒåŸå› " (deliberately vague)
- Expected: Analyst returns SEARCH_REQUIRED â†’ secondary search â†’ finds official statement â†’ produces draft

**Test Case 2: Failed Gap Search**

- Query: Topic with no available information
- Expected: Secondary search returns no results â†’ system hint added â†’ Analyst produces "è³‡è¨Šä¸è¶³" draft

**Test Case 3: Iteration Limit**

- Query: Complex multi-gap query
- Expected: After 3 iterations (including gap searches), system returns best effort with warning

### Phase 4 Testing

**Test Case 1: Time Ambiguity**

- Query: "è”¡è‹±æ–‡çš„å…©å²¸æ”¿ç­–"
- Expected: Clarification modal shows options (2016-2024ä»»å…§ vs å¸ä»»å¾Œè©•åƒ¹)

**Test Case 2: Scope Ambiguity**

- Query: "AI ç™¼å±•"
- Expected: Clarification modal shows options (æŠ€è¡“/ç”¢æ¥­/æ”¿ç­–/å°ç£)

**Test Case 3: No Ambiguity**

- Query: "2024å¹´11æœˆå°ç©é›»é«˜é›„å» æ–°è"
- Expected: No clarification needed, directly proceeds to research

---

## Risk Mitigation

### Risk 1: Secondary Search Latency

**Mitigation**:

- Limit to 20 results per new_query (vs 50 for main search)
- Max 3 new_queries (enforced by Analyst prompt)
- Max 1 gap search per query (built into max_iterations=3)
- **Worst case**: 3 queries Ã— 20 results = 60 results (~2-3 seconds)

### Risk 2: Context Window Explosion

**Mitigation**:

- `_format_context_shared()`Â already has 20k char budget
- Dynamically reduces snippet length if over budget
- Secondary results added to same budget pool

### Risk 3: Infinite Loop

**Mitigation**:

- Each SEARCH_REQUIRED consumes one iteration
- MAX_ITERATIONS = 3 hard limit
- Graceful degradation at limit (return best effort with warning)

---

## Success Criteria

### Phase 5

- [ ] Â Analyst returnsÂ `SEARCH_REQUIRED`Â â†’ secondary search executes automatically
- [ ] Â New results merged into context with updated citation numbers
- [ ] Â Analyst retries with expanded context and produces DRAFT_READY
- [ ] Â Frontend shows "æ­£åœ¨è£œå……æœå°‹..." progress message
- [ ] Â Max 3 iterations total (including gap searches)

### Phase 4

- [ ] Â Ambiguous query triggers clarification modal
- [ ] Â User selects option â†’ query re-submitted with clarified parameters
- [ ] Â Research proceeds with correct time range/scope
- [ ] Â Non-ambiguous queries skip clarification

---

## Implementation Priority

**Week 1**: Phase 5 (Gap Detection) - Higher priority, already partially stubbed

**Week 2**: Phase 4 (Clarification Agent) - Enhances UX but not blocking

**Rationale**: Gap Detection improves research quality for all queries, while Clarification only affects ambiguous queries

---

## Notes

- PDF spec is comprehensive and detailed - follow it closely
- Analyst prompt already instructs gap detection - just need to handle the output
- SSE infrastructure already exists - just add new message types
- Modal infrastructure already exists - just create new modal variant



## Testing Plan

Perfect! Now I have the complete test plan. Based on the document and the previous agent's implementation, let me create a comprehensive testing strategy for you.

## Testing Strategy for Phase 4 & 5

Based on the test plan document and the implemented code, here's how we should test both phases:

---

## **Phase 4: Clarification System Testing**

### **Test Case 1: Time Ambiguity (High Priority)**

**Query**: "è”¡è‹±æ–‡çš„å…©å²¸æ”¿ç­–"

**Expected Behavior**:

1. `deep_research.py`Â detects time parser failure or low confidence
2. `ClarificationAgent.generate_options()`Â generates 2-4 options
3. SSE messageÂ `clarification_required`Â sent to frontend
4. Modal displays options (e.g., "2016-2024ä»»å…§" vs "å¸ä»»å¾Œè©•åƒ¹")
5. User selects option â†’ query re-submitted withÂ `time_range`Â parameter
6. Research proceeds with correct time scope

**How to Test**:

- Submit query via frontend
- Check browser console for SSE message
- Verify modal appears with meaningful options
- Select option and verify query resubmits correctly

---

### **Test Case 2: Scope Ambiguity**

**Query**: "AI ç™¼å±•"

**Expected Behavior**:

1. System detects broad/ambiguous scope
2. Options generated: "æŠ€è¡“ç™¼å±•", "ç”¢æ¥­è¶¨å‹¢", "æ”¿ç­–æ³•è¦", "å°ç£AIç”¢æ¥­"
3. User selects specific scope
4. Research focuses on selected aspect

---

### **Test Case 3: Entity Ambiguity**

**Query**: "æ™¶ç‰‡æ³•æ¡ˆ"

**Expected Behavior**:

1. Multiple entities detected (ç¾åœ‹CHIPSæ³•æ¡ˆ, å°ç£æ™¶ç‰‡æ³•æ¡ˆ, æ­ç›Ÿæ™¶ç‰‡æ³•æ¡ˆ)
2. Clarification options presented
3. User selects specific region
4. Research proceeds with correct entity context

---

### **Test Case 4: No Ambiguity (Negative Test)**

**Query**: "2024å¹´11æœˆå°ç©é›»é«˜é›„å» æ–°è"

**Expected Behavior**:

1. Time parser succeeds (confidence > 0.7)
2. Query is specific enough
3. **NO clarification modal**Â â†’ directly proceeds to research
4. Orchestrator starts immediately

---

## **Phase 5: Gap Detection Testing**

### **Test Case 1: Successful Gap Search**

**Query**: "å°ç©é›»é«˜é›„å» å»¶å¾ŒåŸå› "

**Expected Flow**:

1. Initial search returns 50 results (mostly news reports)
2. Analyst analyzes â†’ detects missing "å®˜æ–¹è²æ˜" or "æŠ€è¡“ç´°ç¯€"
3. ReturnsÂ `status: "SEARCH_REQUIRED"`Â withÂ `new_queries: ["å°ç©é›»å®˜æ–¹è²æ˜ é«˜é›„å» ", "æŠ€è¡“æŒ‘æˆ° é«˜é›„å» "]`
4. Orchestrator executes secondary search (20 results per query)
5. Results merged â†’ context updated with new citation numbers
6. Analyst retries â†’ produces comprehensive draft
7. Frontend shows "ğŸ” æ­£åœ¨è£œå……æœå°‹..." progress

**Verification Points**:

- Check orchestrator logs for "Analyst requested additional search"
- Verify secondary search executes (`gap_search_num_results: 20`)
- Check thatÂ `current_context`Â grows (original 50 + new results)
- Verify citations renumbered correctly
- Confirm frontend SSE handler displays gap search progress

---

### **Test Case 2: Failed Gap Search (Error Handling)**

**Query**: "æœªä¾†ç§‘æŠ€è¶¨å‹¢é æ¸¬" (topic with no concrete information)

**Expected Flow**:

1. Analyst detects gap, requests search
2. Secondary search returnsÂ **0 results**
3. System adds hint: "è£œå……æœå°‹æœªç™¼ç¾æœ‰æ•ˆçµæœï¼Œè«‹åŸºæ–¼ç¾æœ‰è³‡è¨Šæ¨è«–"
4. Analyst forced to produce best-effort draft
5. Critic evaluates (may REJECT or ACCEPT with caveats)

**Verification Points**:

- Check logs for "Secondary search returned no results"
- Verify system hint appended toÂ `formatted_context`
- Confirm Analyst produces output despite no new data
- Writer should include caveat about limited information

---

### **Test Case 3: Iteration Limit (Max 3 Iterations)**

**Query**: "æ°£å€™è®Šé·å°è¾²æ¥­çš„å½±éŸ¿" (complex, multi-faceted topic)

**Expected Flow**:

1. **Iteration 1**: Analyst â†’ SEARCH_REQUIRED (gap: å°ç£æœ¬åœ°æ¡ˆä¾‹)
2. Gap search â†’ retry â†’Â **Iteration 2**: Analyst â†’ SEARCH_REQUIRED (gap: ç¶“æ¿Ÿæ•¸æ“š)
3. Gap search â†’ retry â†’Â **Iteration 3**: Analyst â†’ DRAFT_READY (forced by limit)
4. System returns draft with warning if quality not ideal

**Verification Points**:

- Confirm max 3 iterations enforced (`config_retrieval.yaml`)
- Check graceful degradation at iteration limit
- Verify no infinite loops

---

### **Test Case 4: Gap Search + Critic Rejection (Combined)**

**Query**: "å°ç£åŠå°é«”ç”¢æ¥­çš„åœ‹éš›ç«¶çˆ­åŠ›åˆ†æ"

**Expected Flow**:

1. Initial search â†’ Analyst requests gap search (æŠ€è¡“å„ªå‹¢ç´°ç¯€)
2. Secondary search â†’ expanded context
3. Analyst produces draft
4. Critic:Â **REJECT**Â (ç†ç”±: ç¼ºå°‘èˆ‡éŸ“åœ‹/ä¸­åœ‹çš„æ¯”è¼ƒæ•¸æ“š)
5. **Iteration 2**: Analyst revises â†’ DRAFT_READY
6. Critic:Â **ACCEPT**
7. Writer produces final answer

**Verification Points**:

- Multiple iteration types in one query (gap search + revision)
- Verify iterations tracked correctly
- Check that all progress stages shown in frontend

---

## **How to Execute Tests**

### **Preparation**:

1. **Start the server**:
    
    ```bash
    cd code/python
    python -m webserver.aiohttp_server
    ```
    
2. **Open browser console**Â (F12) to monitor:
    
    - SSE messages
    - Network requests
    - JavaScript errors
3. **Enable verbose logging**:
    
    - CheckÂ `config/config_retrieval.yaml`Â hasÂ `reasoning_params.enabled: true`
    - Set log level to INFO/DEBUG if needed

---

### **Test Execution Workflow**:

For each test case:

1. **Submit query**Â viaÂ `http://localhost:8080/static/news-search-prototype.html`
    
2. **Monitor backend logs**:
    
    ```bash
    # Watch for these key log messages:
    - "Checking for clarification needs..."
    - "Clarification required for query..."
    - "Analyst requested additional search (iteration X)"
    - "Gap search for 'X': Y results"
    - "Added N sources from secondary search"
    ```
    
3. **Monitor frontend**:
    
    - SSE message types in console
    - Reasoning progress updates
    - Modal appearance (Phase 4)
    - Gap search progress (Phase 5)
4. **Verify results**:
    
    - Check final answer quality
    - Verify citations are correct and sequential
    - Confirm no duplicate sources
    - Check iteration count didn't exceed max

---

### **Key Files to Monitor**:

**Backend Logs**:

- `code/python/reasoning/orchestrator.py`Â (gap search flow)
- `code/python/reasoning/agents/clarification.py`Â (option generation)
- `code/python/methods/deep_research.py`Â (pre-search checks)

**Frontend Console**:

- SSE messages (`clarification_required`,Â `gap_search_started`)
- Network tab (checkÂ `/api/chat`Â requests)

**Configuration**:

- `config/config_retrieval.yaml`Â (verify parameters match test expectations)

---

## **Success Checklist**

### Phase 4 (Clarification):

- [ ] Â Ambiguous queries trigger modal
- [ ] Â Modal shows 2-4 meaningful options
- [ ] Â User selection resubmits query correctly
- [ ] Â Non-ambiguous queries skip clarification
- [ ] Â Fallback works if LLM fails to generate options

### Phase 5 (Gap Detection):

- [ ] Â `SEARCH_REQUIRED`Â triggers secondary search automatically
- [ ] Â New results merged with correct citation renumbering
- [ ] Â Frontend shows gap search progress
- [ ] Â Failed searches handled gracefully (system hint)
- [ ] Â Max 3 iterations enforced
- [ ] Â No infinite loops

---

## **Recommended Test Order**:

1. **Phase 4 Test Case 4**Â (negative test - should be fastest)
2. **Phase 4 Test Case 1**Â (time ambiguity - core functionality)
3. **Phase 5 Test Case 1**Â (successful gap search - core functionality)
4. **Phase 5 Test Case 2**Â (failed gap search - error handling)
5. **Phase 4 Test Cases 2-3**Â (other ambiguity types)
6. **Phase 5 Test Cases 3-4**Â (edge cases - iteration limit, combined flows)

---

Would you like me to start testing with you now? We can begin with the simpler test cases and work our way up to the complex ones. Or would you like me to create a test script to automate some of these checks?
