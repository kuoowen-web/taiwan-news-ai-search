# P1.1: Extract Prompt Builders - Detailed Implementation

**Estimated Effort**: 2-3 days
**Impact**: Critical - Removes 2000+ lines of embedded prompts
**ROI**: ⭐⭐⭐⭐⭐

---

## Problem Statement

Currently, prompt text is embedded directly in Python methods, making it impossible to version control prompts separately, difficult to A/B test variants, and hard to maintain.

### Affected Files

1. **`code/python/reasoning/agents/analyst.py:146-796`** (650 lines)
   - Method: `_build_research_prompt()`
   - Contains entire analyst system prompt embedded in Python

2. **`code/python/reasoning/agents/critic.py:119-485`** (367 lines)
   - Method: `_build_review_prompt()`
   - Contains critic review instructions

3. **`code/python/reasoning/agents/writer.py:211-362`** (~150 lines)
   - Method: `_build_compose_prompt()`
   - Contains writer composition instructions

4. **`code/python/methods/deep_research.py:424-562`** (145 lines)
   - Method: `_detect_all_ambiguities()`
   - Contains clarification detection prompt

---

## Solution Architecture

Create a new `reasoning/prompts/` module with:

```
code/python/reasoning/prompts/
├── __init__.py
├── base.py                 # Base builder class + reusable sections
├── analyst.py              # AnalystPromptBuilder
├── critic.py               # CriticPromptBuilder
├── writer.py               # WriterPromptBuilder
└── clarification.py        # ClarificationPromptBuilder
```

---

## Implementation

### Step 1: Create Base Infrastructure

#### File: `code/python/reasoning/prompts/__init__.py`

```python
"""
Prompt builders for reasoning agents.

This module provides structured prompt building for:
- Analyst: Research analysis prompts
- Critic: Review and critique prompts
- Writer: Report composition prompts
- Clarification: Ambiguity detection prompts
"""

from .analyst import build_analyst_prompt, AnalystPromptBuilder
from .critic import build_critic_prompt, CriticPromptBuilder
from .writer import build_writer_prompt, WriterPromptBuilder
from .clarification import build_clarification_prompt, ClarificationPromptBuilder

__all__ = [
    'build_analyst_prompt',
    'AnalystPromptBuilder',
    'build_critic_prompt',
    'CriticPromptBuilder',
    'build_writer_prompt',
    'WriterPromptBuilder',
    'build_clarification_prompt',
    'ClarificationPromptBuilder',
]
```

#### File: `code/python/reasoning/prompts/base.py`

```python
"""Base classes and reusable prompt sections."""

from typing import Dict, List, Any, Optional
from abc import ABC, abstractmethod


class PromptBuilder(ABC):
    """Base class for building structured prompts."""

    def __init__(self):
        self.sections: List[str] = []
        self.metadata: Dict[str, Any] = {}

    def add_section(self, section: str) -> 'PromptBuilder':
        """
        Add a prompt section.

        Args:
            section: Prompt section text (can be multi-line)

        Returns:
            Self for chaining
        """
        if section and section.strip():
            self.sections.append(section.strip())
        return self

    def add_conditional_section(self, condition: bool, section: str) -> 'PromptBuilder':
        """
        Add section only if condition is True.

        Args:
            condition: Whether to include this section
            section: Prompt section text

        Returns:
            Self for chaining
        """
        if condition:
            self.add_section(section)
        return self

    def build(self) -> str:
        """
        Compile all sections into final prompt.

        Returns:
            Complete prompt string with sections joined by double newlines
        """
        return "\n\n".join(self.sections)

    @abstractmethod
    def build_prompt(self, **kwargs) -> str:
        """
        Build the complete prompt with context.

        Must be implemented by subclasses.
        """
        pass


class PromptSection:
    """Reusable prompt sections shared across agents."""

    @staticmethod
    def core_instructions(query: str, mode: str, role: str = "分析師") -> str:
        """Core role and query instructions."""
        return f"""你是一位專業的新聞情報研究{role}。

**使用者查詢**: {query}
**研究模式**: {mode}

請依據以下指示進行分析。"""

    @staticmethod
    def temporal_context(temporal_context: Dict[str, Any]) -> str:
        """Temporal range constraints."""
        if not temporal_context or not temporal_context.get('is_temporal_query'):
            return ""

        start_date = temporal_context.get('start_date', 'N/A')
        end_date = temporal_context.get('end_date', 'N/A')
        method = temporal_context.get('method', 'none')

        return f"""## 時間範圍限制

- 開始日期: {start_date}
- 結束日期: {end_date}
- 解析方法: {method}

**重要**: 僅使用此時間範圍內發布的資訊。超出範圍的內容應明確標註或排除。"""

    @staticmethod
    def citation_rules(item_count: int, mode: str) -> str:
        """Citation formatting and requirements."""
        tier_requirement = {
            "strict": "主要使用 Tier 1-2 來源",
            "discovery": "優先使用 Tier 1-3 來源",
            "monitor": "使用 Tier 1-3 來源"
        }.get(mode, "使用可信來源")

        return f"""## 引用規則

共有 {item_count} 筆資料可供引用 (ID: 1-{item_count})。

**引用格式**: 使用 [數字] 格式，例如: [1], [2,3]
**來源品質**: {tier_requirement}
**引用要求**: 所有事實性陳述都必須包含引用"""

    @staticmethod
    def output_format_json(schema_description: str) -> str:
        """JSON output format requirements."""
        return f"""## 輸出格式

請以 **有效的 JSON 格式** 回應，不要包含任何額外的解釋文字。

{schema_description}

**重要提醒**:
- 確保 JSON 格式正確（所有引號、括號、逗號都要正確）
- 不要在 JSON 外添加任何說明文字
- 確保所有必填欄位都已填寫"""


class ModeInstructions:
    """Mode-specific instructions for different research modes."""

    STRICT = """## Strict 模式特殊要求

這是**事實查核模式**，需要最高標準的證據要求。

**核心原則**:
1. **證據標準**: 僅接受 Tier 1-2 來源作為核心證據
2. **直接引用**: 事實聲明必須有直接引用支持，不可推測
3. **不確定性標註**: 證據不足時，明確標註「無法查證」或「證據不足」
4. **多方驗證**: 關鍵事實需要 2+ 獨立來源交叉確認
5. **時效性**: 優先使用最新資訊，注意資訊發布時間

**拒絕條件**:
- 僅有 Tier 3+ 來源支持的核心主張
- 缺少直接引用的關鍵事實
- 單一來源支持的重要聲明（未經多方驗證）"""

    DISCOVERY = """## Discovery 模式特殊要求

這是**探索性研究模式**，目標是全面理解主題。

**核心原則**:
1. **廣度優先**: 探索多個相關面向和觀點，避免單一視角
2. **連結發現**: 找出不同主題、事件、觀點之間的關聯和模式
3. **新穎洞察**: 提出資料中隱含的趨勢、矛盾或未明確表達的結論
4. **來源多樣性**: 使用多種類型的來源（新聞、專家意見、數據報告等）
5. **平衡呈現**: 如有爭議，公平呈現不同立場

**分析重點**:
- 主題的多個面向（技術、經濟、社會、政治等）
- 不同利益相關者的觀點
- 歷史背景與未來趨勢
- 跨領域影響"""

    MONITOR = """## Monitor 模式特殊要求

這是**動態監測模式**，追蹤事件或觀點的演變。

**核心原則**:
1. **時序分析**: 按時間順序追蹤事件、觀點或數據的變化
2. **變化偵測**: 標示重要的轉折點、趨勢改變或突發事件
3. **對比分析**: 比較不同時間點的狀態，突出差異
4. **預測線索**: 基於歷史趨勢，指出可能的未來走向
5. **連續性**: 建立完整的時間敘事，避免跳躍

**分析架構**:
- 起始狀態（最早的相關資訊）
- 關鍵轉折點（政策改變、重大事件、觀點轉變）
- 當前狀態（最新情況）
- 趨勢方向（可能的發展方向）"""

    @classmethod
    def get(cls, mode: str) -> str:
        """Get mode-specific instructions."""
        mode_map = {
            "strict": cls.STRICT,
            "discovery": cls.DISCOVERY,
            "monitor": cls.MONITOR,
        }
        return mode_map.get(mode, cls.DISCOVERY)
```

---

### Step 2: Create Analyst Prompt Builder

#### File: `code/python/reasoning/prompts/analyst.py`

```python
"""Analyst agent prompt builder."""

from typing import List, Dict, Any, Optional
from .base import PromptBuilder, PromptSection, ModeInstructions


class AnalystPromptBuilder(PromptBuilder):
    """Builder for Analyst agent research prompts."""

    def build_prompt(
        self,
        query: str,
        formatted_context: str,
        mode: str,
        temporal_context: Optional[Dict[str, Any]] = None,
        enable_argument_graph: bool = False,
        enable_knowledge_graph: bool = False,
        enable_gap_enrichment: bool = False,
        enable_web_search: bool = False,
    ) -> str:
        """
        Build complete analyst research prompt.

        Args:
            query: User's research question
            formatted_context: Pre-formatted context with citations
            mode: Research mode (strict, discovery, monitor)
            temporal_context: Optional time range information
            enable_argument_graph: Enable argument graph generation
            enable_knowledge_graph: Enable knowledge graph generation
            enable_gap_enrichment: Enable gap detection
            enable_web_search: Enable web search for dynamic data

        Returns:
            Complete system prompt string
        """
        # Core instructions
        self.add_section(PromptSection.core_instructions(query, mode, "首席分析師 (Lead Analyst)"))

        # Temporal context (if applicable)
        self.add_section(PromptSection.temporal_context(temporal_context or {}))

        # Mode-specific instructions
        self.add_section(ModeInstructions.get(mode))

        # Citation rules
        # Extract item count from formatted_context (count [ID] patterns)
        import re
        citation_matches = re.findall(r'\[(\d+)\]', formatted_context)
        item_count = max([int(m) for m in citation_matches], default=0)
        self.add_section(PromptSection.citation_rules(item_count, mode))

        # Conditional advanced features
        self.add_conditional_section(
            enable_argument_graph,
            self._argument_graph_instructions()
        )

        self.add_conditional_section(
            enable_knowledge_graph,
            self._knowledge_graph_instructions()
        )

        self.add_conditional_section(
            enable_gap_enrichment,
            self._gap_enrichment_instructions(enable_web_search)
        )

        # Add the actual context data
        self.add_section(f"""## 資料來源

{formatted_context}""")

        # Output format
        self.add_section(self._output_format_section(
            enable_argument_graph,
            enable_knowledge_graph,
            enable_gap_enrichment
        ))

        return self.build()

    def _argument_graph_instructions(self) -> str:
        """Instructions for argument graph construction."""
        return """## Argument Graph (論證圖譜) 要求

建構邏輯論證結構，包含主張(Claims)與推理連結(Reasoning)。

### Claim (主張節點)

每個主張應包含:
- `claim_id`: 唯一識別碼 (例: "C1", "C2", "C3")
- `statement`: 主張內容（簡潔、可驗證的陳述）
- `claim_type`: 主張類型
  - `"factual"`: 事實性主張（可驗證的事實）
  - `"causal"`: 因果關係主張（X 導致 Y）
  - `"evaluative"`: 評價性主張（價值判斷）
  - `"predictive"`: 預測性主張（未來可能發生的事）
- `stance`: 相對於查詢主題的立場
  - `"support"`: 支持
  - `"oppose"`: 反對
  - `"neutral"`: 中立/客觀陳述
- `confidence`: 信心水平 (0.0-1.0)
  - 基於證據品質、來源數量、共識程度
- `evidence_ids`: 支持此主張的引用 ID 列表（必須是有效的 ID）

### Reasoning (推理連結)

連結不同主張之間的邏輯關係:
- `reasoning_id`: 唯一識別碼 (例: "R1", "R2")
- `from_claim_id`: 前提主張 ID（必須存在於 claims 中）
- `to_claim_id`: 結論主張 ID（必須存在於 claims 中）
- `reasoning_type`: 推理類型
  - `"deductive"`: 演繹推理（前提真則結論必然真）
  - `"inductive"`: 歸納推理（從特殊到一般）
  - `"abductive"`: 溯因推理（最佳解釋）
  - `"analogical"`: 類比推理
- `strength`: 推理強度 (0.0-1.0)
- `explanation`: 推理邏輯的簡短說明

### 範例

```json
{
  "argument_graph": {
    "claims": [
      {
        "claim_id": "C1",
        "statement": "台積電 2024 年第三季營收創歷史新高",
        "claim_type": "factual",
        "stance": "neutral",
        "confidence": 0.95,
        "evidence_ids": [1, 3]
      },
      {
        "claim_id": "C2",
        "statement": "AI 晶片需求激增是營收成長的主要驅動力",
        "claim_type": "causal",
        "stance": "support",
        "confidence": 0.85,
        "evidence_ids": [3, 5]
      }
    ],
    "reasoning": [
      {
        "reasoning_id": "R1",
        "from_claim_id": "C1",
        "to_claim_id": "C2",
        "reasoning_type": "abductive",
        "strength": 0.8,
        "explanation": "營收成長的最佳解釋是 AI 晶片需求增加"
      }
    ]
  }
}
```

### 驗證規則
- 所有 `evidence_ids` 必須是有效的引用 ID
- `claim_id` 和 `reasoning_id` 必須唯一
- 推理連結的 `from_claim_id` 和 `to_claim_id` 必須在 claims 中存在
- 避免循環推理（A→B→C→A）"""

    def _knowledge_graph_instructions(self) -> str:
        """Instructions for knowledge graph construction."""
        return """## Knowledge Graph (知識圖譜) 要求

建構實體關係網絡，識別關鍵實體及其之間的關係。

### Entity (實體節點)

識別重要的實體對象:
- `entity_id`: 唯一識別碼 (例: "E1", "E2")
- `name`: 實體名稱（正式名稱）
- `entity_type`: 實體類型
  - `"person"`: 人物
  - `"organization"`: 組織/機構/公司
  - `"location"`: 地點/國家/地區
  - `"event"`: 事件
  - `"concept"`: 概念/技術/政策
  - `"product"`: 產品/服務
- `description`: 簡要描述（1-2 句話）
- `attributes`: 屬性字典，記錄重要特徵
  - 例: {"role": "CEO", "founded": "2010", "industry": "半導體"}
- `evidence_ids`: 支持此實體資訊的引用列表

### Relationship (關係連結)

描述實體之間的關係:
- `relationship_id`: 唯一識別碼 (例: "REL1", "REL2")
- `from_entity_id`: 源實體 ID（必須存在於 entities 中）
- `to_entity_id`: 目標實體 ID（必須存在於 entities 中）
- `relationship_type`: 關係類型，例如:
  - `"employed_by"`: 受僱於
  - `"owns"`: 擁有
  - `"located_in"`: 位於
  - `"collaborates_with"`: 合作
  - `"competes_with"`: 競爭
  - `"caused_by"`: 由...引起
  - `"supplies_to"`: 供應給
- `properties`: 關係屬性字典
  - 例: {"since": "2020", "role": "advisor", "stake": "15%"}
- `evidence_ids`: 支持此關係的引用列表

### 範例

```json
{
  "knowledge_graph": {
    "entities": [
      {
        "entity_id": "E1",
        "name": "台積電",
        "entity_type": "organization",
        "description": "全球最大的晶圓代工廠，專注於先進製程技術",
        "attributes": {
          "founded": "1987",
          "headquarters": "新竹",
          "industry": "半導體製造"
        },
        "evidence_ids": [1, 2]
      },
      {
        "entity_id": "E2",
        "name": "NVIDIA",
        "entity_type": "organization",
        "description": "美國 GPU 和 AI 晶片設計公司",
        "attributes": {
          "founded": "1993",
          "headquarters": "Santa Clara",
          "industry": "晶片設計"
        },
        "evidence_ids": [3]
      }
    ],
    "relationships": [
      {
        "relationship_id": "REL1",
        "from_entity_id": "E1",
        "to_entity_id": "E2",
        "relationship_type": "supplies_to",
        "properties": {
          "product": "先進製程晶片",
          "node": "5nm, 3nm"
        },
        "evidence_ids": [3, 5]
      }
    ]
  }
}
```

### 建構指南
- 優先識別查詢相關的核心實體
- 關注實體間有實質意義的關係（避免瑣碎連結）
- 屬性應該是事實性的，有引用支持
- 如有矛盾資訊，在 description 或 attributes 中說明"""

    def _gap_enrichment_instructions(self, enable_web_search: bool) -> str:
        """Instructions for gap detection and enrichment."""
        search_status = "**已啟用**" if enable_web_search else "**未啟用**（僅標註缺口）"

        return f"""## Information Gap Enrichment (資訊缺口偵測)

分析目前資訊的不足之處，並提出補強方案。

Web Search 狀態: {search_status}

### Gap 結構

每個缺口應包含:
- `gap_id`: 唯一識別碼 (例: "G1", "G2")
- `gap_type`: 缺口類型
  - `"missing_perspective"`: 缺少關鍵利益相關者的觀點
  - `"incomplete_data"`: 數據不完整或缺少關鍵數字
  - `"temporal_gap"`: 時間範圍內有空白期或資訊過時
  - `"source_bias"`: 來源過於單一或偏頗
  - `"conflicting_info"`: 資訊矛盾，需要更多證據
- `description`: 缺口的具體描述（1-2 句話）
- `importance`: 重要程度
  - `"critical"`: 關鍵資訊缺失，嚴重影響分析品質
  - `"high"`: 重要資訊缺失，建議補充
  - `"medium"`: 有助於完善分析
  - `"low"`: 可選的補充資訊
- `suggested_search_queries`: 建議的搜尋關鍵字列表（2-3 個）

### 偵測原則

1. **Missing Perspective**:
   - 重要利益相關者未發聲（政府、企業、專家、消費者等）
   - 特定地區或群體的觀點缺失

2. **Incomplete Data**:
   - 提到數據但未給出具體數字
   - 缺少關鍵指標（營收、成長率、市佔率等）
   - 資料時間過舊（超過 6 個月）

3. **Temporal Gap**:
   - 時間線有明顯跳躍
   - 缺少最新發展（如果查詢涉及"最新"）

4. **Source Bias**:
   - 所有來源都來自單一立場
   - 缺少獨立第三方驗證

### 範例

```json
{
  "information_gaps": [
    {
      "gap_id": "G1",
      "gap_type": "incomplete_data",
      "description": "文章提到台積電營收創新高，但未給出具體數字和成長率",
      "importance": "high",
      "suggested_search_queries": [
        "台積電 2024 第三季 營收 具體數字",
        "台積電 Q3 財報 成長率"
      ]
    },
    {
      "gap_id": "G2",
      "gap_type": "missing_perspective",
      "description": "僅有產業分析師觀點，缺少台積電官方說法",
      "importance": "medium",
      "suggested_search_queries": [
        "台積電 官方聲明 2024",
        "台積電 法說會 Q3"
      ]
    }
  ]
}
```

### Web Search 工作流程

{"如果 Web Search 已啟用，你可以在 `information_gaps` 中標註需要搜尋的缺口。系統會自動執行搜尋並在下一輪提供結果。" if enable_web_search else "Web Search 未啟用。僅標註資訊缺口，不會實際執行搜尋。"}"""

    def _output_format_section(
        self,
        enable_argument_graph: bool,
        enable_knowledge_graph: bool,
        enable_gap_enrichment: bool
    ) -> str:
        """Output format requirements."""
        schema_fields = [
            '"summary": "研究摘要 (2-3 句話，概括核心發現)"',
            '"analysis": "詳細分析內容 (markdown 格式，結構化呈現)"',
        ]

        if enable_argument_graph:
            schema_fields.append('"argument_graph": { "claims": [...], "reasoning": [...] }')

        if enable_knowledge_graph:
            schema_fields.append('"knowledge_graph": { "entities": [...], "relationships": [...] }')

        if enable_gap_enrichment:
            schema_fields.append('"information_gaps": [ ... ]')

        schema_fields.extend([
            '"citations_used": [1, 2, 3]  // 本次分析使用的所有引用 ID',
            '"confidence_score": 0.85  // 整體信心水平 (0.0-1.0)',
            '"reasoning_chain": "分析推理過程的簡要說明"'
        ])

        schema = "{\n  " + ",\n  ".join(schema_fields) + "\n}"

        return PromptSection.output_format_json(f"""請使用以下 JSON schema:

```json
{schema}
```

**欄位說明**:
- `summary`: 核心發現的簡潔總結
- `analysis`: 主要分析內容（使用 markdown 格式，包含標題、列表等）
- `citations_used`: 所有引用的 ID（確保都是有效 ID）
- `confidence_score`: 基於證據品質、來源數量、共識程度的整體信心評分
- `reasoning_chain`: 你的分析思路（幫助審查者理解你的邏輯）""")


def build_analyst_prompt(**kwargs) -> str:
    """
    Build analyst prompt (convenience function).

    Args:
        **kwargs: Arguments for AnalystPromptBuilder.build_prompt()

    Returns:
        Complete analyst prompt string
    """
    builder = AnalystPromptBuilder()
    return builder.build_prompt(**kwargs)
```

---

### Step 3: Refactor analyst.py

#### BEFORE (analyst.py:146-796)

The current implementation has a 650-line method with embedded prompt text.

#### AFTER (analyst.py - refactored)

```python
# In code/python/reasoning/agents/analyst.py

# Add import at top of file
from reasoning.prompts.analyst import build_analyst_prompt

# REPLACE lines 146-796 with:
def _build_research_prompt(
    self,
    query: str,
    formatted_context: str,
    mode: str,
    temporal_context: Optional[Dict[str, Any]] = None,
    enable_argument_graph: bool = False,
    enable_knowledge_graph: bool = False,
    enable_gap_enrichment: bool = False,
    enable_web_search: bool = False
) -> str:
    """
    Build research prompt using template builder.

    Args:
        query: User's research question
        formatted_context: Pre-formatted context with [ID] citations
        mode: Research mode (strict, discovery, monitor)
        temporal_context: Optional time range information
        enable_argument_graph: Enable argument graph generation
        enable_knowledge_graph: Enable knowledge graph generation
        enable_gap_enrichment: Enable gap knowledge enrichment
        enable_web_search: Enable web search for dynamic data

    Returns:
        Complete system prompt string
    """
    return build_analyst_prompt(
        query=query,
        formatted_context=formatted_context,
        mode=mode,
        temporal_context=temporal_context,
        enable_argument_graph=enable_argument_graph,
        enable_knowledge_graph=enable_knowledge_graph,
        enable_gap_enrichment=enable_gap_enrichment,
        enable_web_search=enable_web_search,
    )
```

#### Diff

```diff
--- a/code/python/reasoning/agents/analyst.py
+++ b/code/python/reasoning/agents/analyst.py
@@ -1,6 +1,7 @@
 # ... existing imports ...
 from typing import Dict, List, Any, Optional
+from reasoning.prompts.analyst import build_analyst_prompt

 class AnalystAgent:
     # ... existing code ...

@@ -145,653 +146,30 @@ class AnalystAgent:
     def _build_research_prompt(
         self,
         query: str,
         formatted_context: str,
         mode: str,
         temporal_context: Optional[Dict[str, Any]] = None,
         enable_argument_graph: bool = False,
         enable_knowledge_graph: bool = False,
         enable_gap_enrichment: bool = False,
         enable_web_search: bool = False
     ) -> str:
         """
-        Build research prompt from PDF System Prompt (pages 7-10).
+        Build research prompt using template builder.

         Args:
             query: User's research question
             formatted_context: Pre-formatted context with [ID] citations
             mode: Research mode (strict, discovery, monitor)
             temporal_context: Optional time range information
-            enable_argument_graph: Enable argument graph generation (Phase 2)
-            enable_knowledge_graph: Enable knowledge graph generation (Phase KG)
-            enable_gap_enrichment: Enable gap knowledge enrichment (Stage 5)
-            enable_web_search: Enable web search for dynamic data (Stage 5)
+            enable_argument_graph: Enable argument graph generation
+            enable_knowledge_graph: Enable knowledge graph generation
+            enable_gap_enrichment: Enable gap knowledge enrichment
+            enable_web_search: Enable web search for dynamic data

         Returns:
             Complete system prompt string
         """
-        time_range = ""
-        if temporal_context:
-            time_range = f"\n- Time Range: {temporal_context.get('start', 'N/A')} to {temporal_context.get('end', 'N/A')}"
-
-        # ... 650 lines of embedded prompt text removed ...
-
-        return prompt
+        return build_analyst_prompt(
+            query=query,
+            formatted_context=formatted_context,
+            mode=mode,
+            temporal_context=temporal_context,
+            enable_argument_graph=enable_argument_graph,
+            enable_knowledge_graph=enable_knowledge_graph,
+            enable_gap_enrichment=enable_gap_enrichment,
+            enable_web_search=enable_web_search,
+        )
```

---

## Testing

### Unit Tests

Create `tests/test_prompts/test_analyst.py`:

```python
import pytest
from reasoning.prompts.analyst import build_analyst_prompt, AnalystPromptBuilder


def test_analyst_prompt_basic():
    """Test basic prompt generation."""
    prompt = build_analyst_prompt(
        query="台積電 2024 營收",
        formatted_context="[1] 台積電營收創新高\n[2] AI 晶片需求旺盛",
        mode="discovery",
        temporal_context={},
    )

    # Verify core elements present
    assert "台積電 2024 營收" in prompt
    assert "discovery" in prompt.lower() or "Discovery" in prompt
    assert "引用規則" in prompt
    assert "[1]" in prompt  # Context included
    assert "JSON" in prompt  # Output format


def test_analyst_prompt_with_temporal_context():
    """Test prompt with temporal constraints."""
    prompt = build_analyst_prompt(
        query="Test query",
        formatted_context="[1] Test",
        mode="strict",
        temporal_context={
            "is_temporal_query": True,
            "start_date": "2024-01-01",
            "end_date": "2024-12-31",
            "method": "explicit"
        },
    )

    assert "2024-01-01" in prompt
    assert "2024-12-31" in prompt
    assert "時間範圍" in prompt


def test_analyst_prompt_with_argument_graph():
    """Test prompt with argument graph enabled."""
    prompt = build_analyst_prompt(
        query="Test",
        formatted_context="[1] Test",
        mode="strict",
        temporal_context={},
        enable_argument_graph=True,
    )

    assert "Argument Graph" in prompt or "論證圖譜" in prompt
    assert "claim_id" in prompt
    assert "reasoning" in prompt.lower()


def test_analyst_prompt_with_knowledge_graph():
    """Test prompt with knowledge graph enabled."""
    prompt = build_analyst_prompt(
        query="Test",
        formatted_context="[1] Test",
        mode="discovery",
        temporal_context={},
        enable_knowledge_graph=True,
    )

    assert "Knowledge Graph" in prompt or "知識圖譜" in prompt
    assert "entity_id" in prompt
    assert "relationship" in prompt.lower()


def test_analyst_prompt_with_gap_enrichment():
    """Test prompt with gap enrichment enabled."""
    prompt = build_analyst_prompt(
        query="Test",
        formatted_context="[1] Test",
        mode="discovery",
        temporal_context={},
        enable_gap_enrichment=True,
        enable_web_search=True,
    )

    assert "Gap" in prompt or "缺口" in prompt
    assert "已啟用" in prompt  # Web search enabled
    assert "search_query" in prompt.lower()


def test_analyst_prompt_mode_specific_instructions():
    """Test that mode-specific instructions are included."""
    for mode in ["strict", "discovery", "monitor"]:
        prompt = build_analyst_prompt(
            query="Test",
            formatted_context="[1] Test",
            mode=mode,
            temporal_context={},
        )

        assert mode in prompt.lower()


def test_analyst_prompt_builder_chaining():
    """Test builder pattern chaining."""
    builder = AnalystPromptBuilder()

    result = (builder
        .add_section("Section 1")
        .add_section("Section 2")
        .add_conditional_section(True, "Section 3")
        .add_conditional_section(False, "Should not appear")
    )

    assert result is builder  # Chaining returns self

    final = builder.build()
    assert "Section 1" in final
    assert "Section 2" in final
    assert "Section 3" in final
    assert "Should not appear" not in final


def test_analyst_prompt_citation_count_extraction():
    """Test that citation count is correctly extracted."""
    prompt = build_analyst_prompt(
        query="Test",
        formatted_context="[1] First\n[2] Second\n[5] Fifth",
        mode="discovery",
        temporal_context={},
    )

    # Should detect maximum citation ID (5)
    assert "1-5" in prompt or "ID: 1-5" in prompt
```

### Integration Test

Create `tests/integration/test_analyst_refactor.py`:

```python
import pytest
from reasoning.agents.analyst import AnalystAgent
from core.llm import MockLLMClient


@pytest.fixture
def analyst_agent():
    """Create analyst agent with mock LLM client."""
    config = {"analyst_model": "gpt-4"}
    llm_client = MockLLMClient()
    logger = logging.getLogger("test")

    return AnalystAgent(config, llm_client, logger)


def test_analyst_prompt_generation_unchanged(analyst_agent):
    """Verify refactored prompt generation produces equivalent results."""
    query = "台積電 2024 Q3 財報"
    formatted_context = "[1] 台積電營收創新高\n[2] AI 晶片需求旺盛"
    mode = "discovery"

    prompt = analyst_agent._build_research_prompt(
        query=query,
        formatted_context=formatted_context,
        mode=mode,
    )

    # Verify essential components
    assert query in prompt
    assert "discovery" in prompt.lower()
    assert "[1]" in prompt
    assert "[2]" in prompt
    assert "JSON" in prompt


def test_analyst_end_to_end_with_refactored_prompts(analyst_agent):
    """Test full analyst workflow with refactored prompts."""
    # This test ensures the refactor doesn't break the actual agent behavior
    items = [
        {"id": 1, "title": "台積電 Q3 營收創新高", "description": "..."},
        {"id": 2, "title": "AI 晶片需求旺盛", "description": "..."},
    ]

    result = await analyst_agent.analyze(
        query="台積電 2024 Q3 財報",
        mode="discovery",
        items=items,
        temporal_context={},
    )

    # Verify result structure (agent behavior unchanged)
    assert "summary" in result or "analysis" in result
```

---

## Implementation Steps

1. **Create new prompt module structure** (30 min)
   ```bash
   mkdir -p code/python/reasoning/prompts
   touch code/python/reasoning/prompts/__init__.py
   ```

2. **Implement base infrastructure** (2 hours)
   - Create `base.py` with PromptBuilder, PromptSection, ModeInstructions
   - Write unit tests for base classes

3. **Implement AnalystPromptBuilder** (4 hours)
   - Create `analyst.py` with full prompt builder
   - Extract all prompt sections from current analyst.py
   - Write comprehensive unit tests

4. **Refactor analyst.py** (1 hour)
   - Replace 650-line method with 20-line delegator
   - Update imports
   - Run tests to verify behavior unchanged

5. **Repeat for other agents** (1 day)
   - Critic prompt builder (similar structure)
   - Writer prompt builder
   - Clarification prompt builder

6. **Integration testing** (2 hours)
   - End-to-end tests with real agents
   - Regression testing
   - Performance verification

7. **Documentation** (1 hour)
   - Update CLAUDE.md
   - Add README to prompts/ module
   - Document prompt versioning strategy

---

## Benefits Achieved

- ✅ **2000+ lines removed** from agent files
- ✅ **Prompts versionable** in git (separate commits for prompt changes)
- ✅ **Easy A/B testing** (swap prompt builders)
- ✅ **Better maintainability** (prompts readable without Python noise)
- ✅ **Reusable components** (ModeInstructions, PromptSection shared)
- ✅ **Testable in isolation** (unit test prompts without agents)

---

## Migration Checklist

- [ ] Create `reasoning/prompts/` module structure
- [ ] Implement `base.py` with PromptBuilder
- [ ] Implement `analyst.py` with AnalystPromptBuilder
- [ ] Write unit tests for analyst prompts
- [ ] Refactor `analyst.py` to use builder
- [ ] Run integration tests
- [ ] Implement `critic.py` builder
- [ ] Implement `writer.py` builder
- [ ] Implement `clarification.py` builder
- [ ] Update all agent files to use builders
- [ ] Full regression test suite
- [ ] Update documentation
- [ ] Code review
- [ ] Merge to main

---

## Next Steps

After completing P1.1, proceed to:
- **P1.2**: Refactor Orchestrator (see separate document)
- **P1.3**: Simplify Deep Research (see separate document)
